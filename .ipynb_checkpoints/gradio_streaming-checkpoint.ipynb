{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b30e428-f689-47ef-a9b2-53905fad7387",
   "metadata": {},
   "source": [
    "This dependency is necessary for whisper with Huggingface, but is not necessary for whisper with faster-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dea40c-3f32-420e-9e49-1cf613a3d2df",
   "metadata": {},
   "source": [
    "> apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dacd0d5-4f97-40f2-948c-b0f2e7545fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T16:00:07.626560Z",
     "iopub.status.busy": "2024-06-29T16:00:07.626243Z",
     "iopub.status.idle": "2024-06-29T16:00:07.631799Z",
     "shell.execute_reply": "2024-06-29T16:00:07.630621Z",
     "shell.execute_reply.started": "2024-06-29T16:00:07.626535Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acb2ef-2b38-4149-85ab-eac5f566c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4380ce-3f9a-4bd7-be08-f04eae90edcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T19:54:36.680822Z",
     "iopub.status.busy": "2024-06-28T19:54:36.680509Z",
     "iopub.status.idle": "2024-06-28T19:54:36.692520Z",
     "shell.execute_reply": "2024-06-28T19:54:36.691542Z",
     "shell.execute_reply.started": "2024-06-28T19:54:36.680800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.37.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37208fa3-fe1e-4255-820c-26b3a9ef5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae56fa1-92c1-49eb-b571-539616487108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T19:55:09.440272Z",
     "iopub.status.busy": "2024-06-28T19:55:09.439899Z",
     "iopub.status.idle": "2024-06-28T19:55:09.451993Z",
     "shell.execute_reply": "2024-06-28T19:55:09.450948Z",
     "shell.execute_reply.started": "2024-06-28T19:55:09.440240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.42.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42285c4e-c3bc-4fb9-bf01-c9d6ab1312a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:01:15.267601Z",
     "iopub.status.busy": "2024-06-29T17:01:15.266085Z",
     "iopub.status.idle": "2024-06-29T17:01:20.484640Z",
     "shell.execute_reply": "2024-06-29T17:01:20.484106Z",
     "shell.execute_reply.started": "2024-06-29T17:01:15.267555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 (24000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription executed in 1495.54 ms\n",
      "48000 (96000,)\n",
      "Transcription executed in 726.83 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 630.95 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 594.23 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 797.05 ms\n",
      "48000 (72000,)\n",
      "Transcription executed in 1081.01 ms\n",
      "48000 (72000,)\n",
      "Transcription executed in 1216.34 ms\n",
      "48000 (96000,)\n",
      "Transcription executed in 1487.10 ms\n",
      "48000 (96000,)\n",
      "Transcription executed in 1671.09 ms\n",
      "48000 (96000,)\n",
      "Transcription executed in 2235.63 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 (120000,)\n",
      "Transcription executed in 2695.22 ms\n",
      "48000 (144000,)\n",
      "Transcription executed in 3254.47 ms\n",
      "48000 (168000,)\n",
      "Transcription executed in 3241.85 ms\n",
      "48000 (140640,)\n",
      "Transcription executed in 3160.29 ms\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\", model_kwargs={}, generate_kwargs = {\"task\":\"transcribe\", \"language\":\"french\"}, device=0)\n",
    "\n",
    "class RollingAudioBuffer:\n",
    "    def __init__(self, max_length_sec, sampling_rate):\n",
    "        self.buffer = np.empty((0,), dtype=np.float32)\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.max_length = max_length_sec * sampling_rate\n",
    "\n",
    "    def add_samples(self, np_samples):\n",
    "        self.buffer = np.concatenate((self.buffer, np_samples))\n",
    "        if len(self.buffer) > self.max_length:\n",
    "            self.buffer = self.buffer[len(self.buffer)-self.max_length:]\n",
    "\n",
    "audiobuffer = RollingAudioBuffer(max_length_sec=25, sampling_rate=48000)\n",
    "\n",
    "def transcribe(audio):\n",
    "    # Get audio stream from gr.Audio component: int16\n",
    "    sampling_rate, np_samples = audio\n",
    "    print(sampling_rate, np_samples.shape)\n",
    "\n",
    "    # Convert audio stream to whisper format: fp32 between -1 and 1\n",
    "    np_samples = np_samples.astype(np.float32)\n",
    "    np_samples /= np.max(np.abs(np_samples))\n",
    "\n",
    "    # Accumulate audio samples in buffer\n",
    "    audiobuffer.add_samples(np_samples)\n",
    "    \n",
    "    # Convert audio stream to text\n",
    "    start_time = time.time()\n",
    "    text = transcriber({\"sampling_rate\": sampling_rate, \"raw\": audiobuffer.buffer})[\"text\"]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Transcription executed in {elapsed_time*1000:.2f} ms\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\"], streaming=True),\n",
    "    \"text\",\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca0b5f-b574-404c-b009-eb8e91371002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4346287e-57e4-4728-befc-f10b9d85aff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T16:00:29.385255Z",
     "iopub.status.busy": "2024-06-29T16:00:29.384232Z",
     "iopub.status.idle": "2024-06-29T16:00:29.394359Z",
     "shell.execute_reply": "2024-06-29T16:00:29.393757Z",
     "shell.execute_reply.started": "2024-06-29T16:00:29.385208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('faster-whisper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2950c49f-b762-4f77-a169-ee2b05139d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T16:37:49.724262Z",
     "iopub.status.busy": "2024-06-29T16:37:49.723791Z",
     "iopub.status.idle": "2024-06-29T16:37:49.732590Z",
     "shell.execute_reply": "2024-06-29T16:37:49.731586Z",
     "shell.execute_reply.started": "2024-06-29T16:37:49.724229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220800,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audiobuffer.buffer[::4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbfca2c0-40b9-4a50-b96f-e71ec1c7eeb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:02:29.904125Z",
     "iopub.status.busy": "2024-06-29T17:02:29.903749Z",
     "iopub.status.idle": "2024-06-29T17:02:32.896753Z",
     "shell.execute_reply": "2024-06-29T17:02:32.896043Z",
     "shell.execute_reply.started": "2024-06-29T17:02:29.904103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Le 30 juin et le 7 juillet prochain se tiendra dans notre circonscription et partout en France une nouvelle élection législative. J'y suis candidat. Depuis 7 ans, j'ai défendu à l'assandé nationale des positions forgées par mes convictions et par nos échanges que j'ai toujours voulu constant et nombreux.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber({\"sampling_rate\": audiobuffer.sampling_rate/4, \"raw\": audiobuffer.buffer[::4]})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781d5c0d-5701-49ed-95d3-d736f8696f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:12:53.826764Z",
     "iopub.status.busy": "2024-06-29T17:12:53.826226Z",
     "iopub.status.idle": "2024-06-29T17:12:58.716200Z",
     "shell.execute_reply": "2024-06-29T17:12:58.715324Z",
     "shell.execute_reply.started": "2024-06-29T17:12:53.826731Z"
    }
   },
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# distill-large-v3 : english only, 1.5GB, 750 ms\n",
    "\n",
    "# model_size = \"tiny\" # 20 sec -> 1.24 sec - too many errors\n",
    "# model_size = \"base\" # 20 sec -> 1.72 sec vs 3 sec with huggingface\n",
    "# model_size = \"small\" # 20 sec -> 4.18 sec\n",
    "# model_size = \"large-v3\" # 20 sec -> 16.33 sec\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aff72f64-ff57-4022-a5d6-31d115c100ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:13:00.979868Z",
     "iopub.status.busy": "2024-06-29T17:13:00.979388Z",
     "iopub.status.idle": "2024-06-29T17:13:17.309262Z",
     "shell.execute_reply": "2024-06-29T17:13:17.308752Z",
     "shell.execute_reply.started": "2024-06-29T17:13:00.979850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 6.64s]  Cher monsieur, le 30 juin et le 7 juillet prochains se tiendra dans notre circonscription et partout en France une nouvelle élection législative.\n",
      "[7.22s -> 7.98s]  J'y suis candidat.\n",
      "[8.50s -> 14.26s]  Depuis 7 ans, j'ai défendu à l'Assemblée nationale des positions forgées par mes convictions et par nos échanges que j'ai toujours voulu constants et nombreux.\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(audiobuffer.buffer[::4], beam_size=5, language=\"fr\", condition_on_previous_text=False, vad_filter=True, vad_parameters=dict(min_silence_duration_ms=500))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f99ea-d9bf-4e75-964e-1314cb55716d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
