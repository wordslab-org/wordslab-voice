{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0269d88-e7f0-4d57-820d-af5403281b65",
   "metadata": {},
   "source": [
    "We will use a rolling audio buffer with a limited duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05032d8f-2cfe-4538-9196-fc498c837bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:05:12.418063Z",
     "iopub.status.busy": "2024-07-06T14:05:12.416728Z",
     "iopub.status.idle": "2024-07-06T14:05:12.513513Z",
     "shell.execute_reply": "2024-07-06T14:05:12.513031Z",
     "shell.execute_reply.started": "2024-07-06T14:05:12.418034Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class RollingAudioBuffer:\n",
    "    def __init__(self, max_length_sec, sampling_rate):\n",
    "        self.buffer = np.empty((0,), dtype=np.float32)\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.max_length = max_length_sec * sampling_rate\n",
    "\n",
    "    def add_samples(self, np_samples):\n",
    "        self.buffer = np.concatenate((self.buffer, np_samples))\n",
    "        if len(self.buffer) > self.max_length:\n",
    "            self.buffer = self.buffer[len(self.buffer)-self.max_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962d4b5-e561-4eaa-ada6-3337b3721e3d",
   "metadata": {},
   "source": [
    "Load test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d64ace-a949-40e5-a88e-199077fe23f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:05:13.911242Z",
     "iopub.status.busy": "2024-07-06T14:05:13.910842Z",
     "iopub.status.idle": "2024-07-06T14:05:13.917837Z",
     "shell.execute_reply": "2024-07-06T14:05:13.917190Z",
     "shell.execute_reply.started": "2024-07-06T14:05:13.911218Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobuffer = RollingAudioBuffer(max_length_sec=25, sampling_rate=48000)\n",
    "audiobuffer.buffer = np.load(\"test_en.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ee8be-4642-4ed2-8e18-a9529ea6e300",
   "metadata": {},
   "source": [
    "# 1. Huggingface automatic-speech-recognition pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5d533-b622-4b7c-9a02-7588e999d8fb",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30e428-f689-47ef-a9b2-53905fad7387",
   "metadata": {},
   "source": [
    "This dependency is necessary for whisper with Huggingface, but is not necessary for whisper with faster-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dea40c-3f32-420e-9e49-1cf613a3d2df",
   "metadata": {},
   "source": [
    "> apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb745167-5f0e-4ca1-86cc-861def45e453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:36:20.883429Z",
     "iopub.status.busy": "2024-07-06T13:36:20.883189Z",
     "iopub.status.idle": "2024-07-06T13:36:21.018285Z",
     "shell.execute_reply": "2024-07-06T13:36:21.016922Z",
     "shell.execute_reply.started": "2024-07-06T13:36:20.883414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "libavutil      56. 51.100 / 56. 51.100\n",
      "libavcodec     58. 91.100 / 58. 91.100\n",
      "libavformat    58. 45.100 / 58. 45.100\n",
      "libavdevice    58. 10.100 / 58. 10.100\n",
      "libavfilter     7. 85.100 /  7. 85.100\n",
      "libavresample   4.  0.  0 /  4.  0.  0\n",
      "libswscale      5.  7.100 /  5.  7.100\n",
      "libswresample   3.  7.100 /  3.  7.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dacd0d5-4f97-40f2-948c-b0f2e7545fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:27:41.757100Z",
     "iopub.status.busy": "2024-07-06T13:27:41.756800Z",
     "iopub.status.idle": "2024-07-06T13:27:41.761390Z",
     "shell.execute_reply": "2024-07-06T13:27:41.760479Z",
     "shell.execute_reply.started": "2024-07-06T13:27:41.757073Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37208fa3-fe1e-4255-820c-26b3a9ef5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae56fa1-92c1-49eb-b571-539616487108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:19:13.423201Z",
     "iopub.status.busy": "2024-07-06T13:19:13.422793Z",
     "iopub.status.idle": "2024-07-06T13:19:13.433113Z",
     "shell.execute_reply": "2024-07-06T13:19:13.432365Z",
     "shell.execute_reply.started": "2024-07-06T13:19:13.423168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.42.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db5be-d7d2-4c80-9a9f-88c5b071426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f8c895-4fca-4cf9-b25b-45848406584b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:19:58.777585Z",
     "iopub.status.busy": "2024-07-06T13:19:58.776618Z",
     "iopub.status.idle": "2024-07-06T13:19:58.786530Z",
     "shell.execute_reply": "2024-07-06T13:19:58.785840Z",
     "shell.execute_reply.started": "2024-07-06T13:19:58.777535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.9.post1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('flash_attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941643f3-348c-4ab6-8cc9-0b4b2b7f1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15aa5d0e-9fa4-4626-a9b8-0a54f519f4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:27:43.810808Z",
     "iopub.status.busy": "2024-07-06T13:27:43.810435Z",
     "iopub.status.idle": "2024-07-06T13:27:43.819611Z",
     "shell.execute_reply": "2024-07-06T13:27:43.819027Z",
     "shell.execute_reply.started": "2024-07-06T13:27:43.810791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.32.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('accelerate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ce54d-74d3-48db-894d-2a02a082fd9c",
   "metadata": {},
   "source": [
    "## Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cbc6d-3101-45f2-a3f4-0b75f47f4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\", \n",
    "                       model_kwargs={\"torch_dtype\":torch.float16, \"attn_implementation\":\"flash_attention_2\", \"device_map\":0}, \n",
    "                       generate_kwargs = {\"task\":\"transcribe\", \"language\":\"english\"})\n",
    "\n",
    "transcriber.model.model = torch.compile(transcriber.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b5f2c5-e34f-4d28-bb0e-53b2f1f66618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:07:01.753785Z",
     "iopub.status.busy": "2024-07-06T14:07:01.753176Z",
     "iopub.status.idle": "2024-07-06T14:07:02.768161Z",
     "shell.execute_reply": "2024-07-06T14:07:02.767670Z",
     "shell.execute_reply.started": "2024-07-06T14:07:01.753769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà. Y'a trouvé pas? Ouais, j'ai\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber({\"sampling_rate\": audiobuffer.sampling_rate, \"raw\": audiobuffer.buffer})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5773f50-3d76-4bb2-8698-6e2ea392f414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:07:09.004549Z",
     "iopub.status.busy": "2024-07-06T14:07:09.003679Z",
     "iopub.status.idle": "2024-07-06T14:07:09.822319Z",
     "shell.execute_reply": "2024-07-06T14:07:09.821738Z",
     "shell.execute_reply.started": "2024-07-06T14:07:09.004519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber({\"sampling_rate\": audiobuffer.sampling_rate/4, \"raw\": audiobuffer.buffer[::4]})[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9f9bc-3612-4505-92e5-bee06c2ce2a8",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d42864-f44e-4048-a86d-af2d34baa7df",
   "metadata": {},
   "source": [
    "whisper-small\n",
    "- basic huggingface pipeline: 5.92 sec\n",
    "- with 16 bits & flash attention: 2.42 sec\n",
    "- and with torch.compile: 2.25 sec\n",
    "- then plugged: 1.07 sec\n",
    "- then divide sampling rate by 4: 800-900 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeabad2-a4c7-468d-a868-4b51696278df",
   "metadata": {},
   "source": [
    "# 2. Systran faster-whisper with ctranslate2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b4eae-5990-4116-a281-ed7baddd1d41",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "131f1076-1603-4d7f-8928-da2bbfee9fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:44:40.326771Z",
     "iopub.status.busy": "2024-07-06T13:44:40.326337Z",
     "iopub.status.idle": "2024-07-06T13:44:40.329433Z",
     "shell.execute_reply": "2024-07-06T13:44:40.328784Z",
     "shell.execute_reply.started": "2024-07-06T13:44:40.326755Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca0b5f-b574-404c-b009-eb8e91371002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4346287e-57e4-4728-befc-f10b9d85aff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:44:41.952371Z",
     "iopub.status.busy": "2024-07-06T13:44:41.951601Z",
     "iopub.status.idle": "2024-07-06T13:44:41.960559Z",
     "shell.execute_reply": "2024-07-06T13:44:41.960039Z",
     "shell.execute_reply.started": "2024-07-06T13:44:41.952341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('faster-whisper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628ac67-932c-4796-b43f-53ba77946988",
   "metadata": {},
   "source": [
    "## Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781d5c0d-5701-49ed-95d3-d736f8696f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:07:50.844384Z",
     "iopub.status.busy": "2024-07-06T14:07:50.843985Z",
     "iopub.status.idle": "2024-07-06T14:07:51.593589Z",
     "shell.execute_reply": "2024-07-06T14:07:51.592714Z",
     "shell.execute_reply.started": "2024-07-06T14:07:50.844365Z"
    }
   },
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# distill-large-v3 : english only, 1.5GB, 750 ms\n",
    "# model_size = \"tiny\" # 20 sec -> 1.24 sec - too many errors\n",
    "# model_size = \"base\" # 20 sec -> 1.72 sec vs 3 sec with huggingface\n",
    "# model_size = \"small\" # 20 sec -> 4.18 sec\n",
    "# model_size = \"large-v3\" # 20 sec -> 16.33 sec\n",
    "\n",
    "model = WhisperModel(\"small\", device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff72f64-ff57-4022-a5d6-31d115c100ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:08:11.620966Z",
     "iopub.status.busy": "2024-07-06T14:08:11.620627Z",
     "iopub.status.idle": "2024-07-06T14:08:12.239475Z",
     "shell.execute_reply": "2024-07-06T14:08:12.238857Z",
     "shell.execute_reply.started": "2024-07-06T14:08:11.620946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08s -> 7.44s]  So I am on a website to try and find a job and I had to answer to some questions\n",
      "[7.44s -> 14.24s]  And I had to say what I was studying and I had some difficulties to find the good the topic and\n",
      "[15.92s -> 18.46s]  Yeah\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(audiobuffer.buffer[::4], beam_size=5, language=\"en\", condition_on_previous_text=False, vad_filter=True, vad_parameters=dict(min_silence_duration_ms=500))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f773c4-672b-4121-bd0d-b0bd0ef7eddb",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a08729-62e6-454b-88de-e7273bf599f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:47:13.827690Z",
     "iopub.status.busy": "2024-07-06T13:47:13.827044Z",
     "iopub.status.idle": "2024-07-06T13:47:13.831857Z",
     "shell.execute_reply": "2024-07-06T13:47:13.831224Z",
     "shell.execute_reply.started": "2024-07-06T13:47:13.827666Z"
    }
   },
   "source": [
    "whisper-small\n",
    "- sampling rate divided by 4: 618 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ac740-dda6-46ad-aa48-8646b3bb6e93",
   "metadata": {},
   "source": [
    "# 3. Translation with Helsinki-NLP/opus-mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd131d-2ffb-46cb-a3d2-8966c6f9087a",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3058dc-6d2e-4a94-ab23-87a11c3896d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:10:11.034155Z",
     "iopub.status.busy": "2024-07-06T14:10:11.033883Z",
     "iopub.status.idle": "2024-07-06T14:10:11.037264Z",
     "shell.execute_reply": "2024-07-06T14:10:11.036740Z",
     "shell.execute_reply.started": "2024-07-06T14:10:11.034137Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd8f64-8bfe-47a2-90ce-122cac596eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8613669-d990-4245-993b-0f1193b7d08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:50:56.827089Z",
     "iopub.status.busy": "2024-07-06T13:50:56.826875Z",
     "iopub.status.idle": "2024-07-06T13:50:56.833001Z",
     "shell.execute_reply": "2024-07-06T13:50:56.832424Z",
     "shell.execute_reply.started": "2024-07-06T13:50:56.827075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sentencepiece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cceb8b9-0d53-4e16-a8e0-9cb2d5a4e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61ad5a5-8fa8-4035-a0c3-22482e1d6d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:10:12.760931Z",
     "iopub.status.busy": "2024-07-06T14:10:12.760609Z",
     "iopub.status.idle": "2024-07-06T14:10:12.769178Z",
     "shell.execute_reply": "2024-07-06T14:10:12.768670Z",
     "shell.execute_reply.started": "2024-07-06T14:10:12.760909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sacremoses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061aaf1-8b7c-4d74-905c-5f672adfe0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:08:42.010912Z",
     "iopub.status.busy": "2024-07-06T14:08:42.010537Z",
     "iopub.status.idle": "2024-07-06T14:08:42.016888Z",
     "shell.execute_reply": "2024-07-06T14:08:42.015642Z",
     "shell.execute_reply.started": "2024-07-06T14:08:42.010887Z"
    }
   },
   "source": [
    "## Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "525f99ea-d9bf-4e75-964e-1314cb55716d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:10:15.244675Z",
     "iopub.status.busy": "2024-07-06T14:10:15.243941Z",
     "iopub.status.idle": "2024-07-06T14:10:16.775170Z",
     "shell.execute_reply": "2024-07-06T14:10:16.774538Z",
     "shell.execute_reply.started": "2024-07-06T14:10:15.244653Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name, )\n",
    "\n",
    "# Prepare the input text\n",
    "def translate_texts(src_texts):\n",
    "    encoded = tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Perform the translation\n",
    "    translated = model.generate(**encoded)\n",
    "    tgt_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "    return tgt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88a1087c-d086-4315-b41a-27c284dc11d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:10:30.162327Z",
     "iopub.status.busy": "2024-07-06T14:10:30.162043Z",
     "iopub.status.idle": "2024-07-06T14:10:30.755791Z",
     "shell.execute_reply": "2024-07-06T14:10:30.754967Z",
     "shell.execute_reply.started": "2024-07-06T14:10:30.162307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà!\n",
      "Translated: Donc je suis sur un site web pour essayer de trouver un emploi et j'ai dû répondre à certaines questions et j'ai dû dire ce que j'étudiais et j'ai eu quelques difficultés à trouver le bon sujet et le... voilà!\n"
     ]
    }
   ],
   "source": [
    "# Test the translations\n",
    "src_texts = [\"So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà!\"]\n",
    "tgt_texts = translate_texts(src_texts)\n",
    "\n",
    "for src, tgt in zip(src_texts, tgt_texts):\n",
    "    print(f\"Source: {src}\")\n",
    "    print(f\"Translated: {tgt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fcea3-1c70-40c9-9cd6-6bc88b940153",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaac3ad-6919-44d5-a0a2-89510a9a8485",
   "metadata": {},
   "source": [
    "opus-mt-en-fr\n",
    "- 592 ms\n",
    "\n",
    "Note: MarianMTModel doesn't support flash attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee27a8d-e3f0-4694-9b22-d44bf31dbb84",
   "metadata": {},
   "source": [
    "# 4. Real-time speech transcription UI with gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea6f7f-4f58-4b1f-9245-5594f5c1001d",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acb2ef-2b38-4149-85ab-eac5f566c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad4380ce-3f9a-4bd7-be08-f04eae90edcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:11:18.112052Z",
     "iopub.status.busy": "2024-07-06T14:11:18.111705Z",
     "iopub.status.idle": "2024-07-06T14:11:18.119328Z",
     "shell.execute_reply": "2024-07-06T14:11:18.118771Z",
     "shell.execute_reply.started": "2024-07-06T14:11:18.112029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.37.2'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('gradio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6af53-d400-45af-b45b-22184ec6cfb5",
   "metadata": {},
   "source": [
    "## Display UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddf2017a-20af-4ca8-829b-9de3bc7c02a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:12:17.957844Z",
     "iopub.status.busy": "2024-07-06T14:12:17.957518Z",
     "iopub.status.idle": "2024-07-06T14:12:18.063223Z",
     "shell.execute_reply": "2024-07-06T14:12:18.062718Z",
     "shell.execute_reply.started": "2024-07-06T14:12:17.957821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 (24000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription executed in 266.19 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 140.58 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 120.30 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 182.59 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 184.64 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 (24000,)\n",
      "Transcription executed in 237.20 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 268.52 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 296.22 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 297.93 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 336.71 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 416.45 ms\n",
      "48000 (24000,)\n",
      "Transcription executed in 380.45 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 413.32 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 573.85 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 528.43 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 562.93 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 664.57 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 691.68 ms\n",
      "48000 (48000,)\n",
      "Transcription executed in 687.75 ms\n",
      "48000 (48960,)\n",
      "Transcription executed in 495.76 ms\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "audiobuffer = RollingAudioBuffer(max_length_sec=25, sampling_rate=48000)\n",
    "\n",
    "def transcribe(audio):\n",
    "    # Get audio stream from gr.Audio component: int16\n",
    "    sampling_rate, np_samples = audio\n",
    "    print(sampling_rate, np_samples.shape)\n",
    "\n",
    "    # Convert audio stream to whisper format: fp32 between -1 and 1\n",
    "    np_samples = np_samples.astype(np.float32)\n",
    "    np_samples /= np.max(np.abs(np_samples))\n",
    "\n",
    "    # Accumulate audio samples in buffer\n",
    "    audiobuffer.add_samples(np_samples)\n",
    "    \n",
    "    # Convert audio stream to text\n",
    "    start_time = time.time()\n",
    "    text = transcriber({\"sampling_rate\": sampling_rate, \"raw\": audiobuffer.buffer})[\"text\"]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Transcription executed in {elapsed_time*1000:.2f} ms\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\"], streaming=True),\n",
    "    \"text\",\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd933556-b3da-4021-90ed-f9b7cf9f672a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:02:37.669029Z",
     "iopub.status.busy": "2024-07-06T14:02:37.667845Z",
     "iopub.status.idle": "2024-07-06T14:02:37.685561Z",
     "shell.execute_reply": "2024-07-06T14:02:37.684997Z",
     "shell.execute_reply.started": "2024-07-06T14:02:37.669000Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"test_en.npy\", audiobuffer.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
