{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd66fbdb-5fed-4b9f-9f76-8351102f616d",
   "metadata": {},
   "source": [
    "# Real-time speech transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968adba8-b4dc-4541-b5ba-339a8e8af1bd",
   "metadata": {},
   "source": [
    "## Audio buffer management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0269d88-e7f0-4d57-820d-af5403281b65",
   "metadata": {},
   "source": [
    "The audio samples for real-time speech transcription will be accumulated in a rolling audio buffer with a limited duration (< 30 sec for whsiper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05032d8f-2cfe-4538-9196-fc498c837bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:14.808077Z",
     "iopub.status.busy": "2024-07-10T19:26:14.807762Z",
     "iopub.status.idle": "2024-07-10T19:26:15.027664Z",
     "shell.execute_reply": "2024-07-10T19:26:15.027048Z",
     "shell.execute_reply.started": "2024-07-10T19:26:14.808048Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 1. Aggregates audio samples in a buffer and keeps only the last max_length_sec seconds.\n",
    "# 2. Converts the audio format from input to output sampling rate and dtype.\n",
    "class RollingAudioBuffer:\n",
    "\n",
    "    # Default max length (whisper): 30 sec\n",
    "    # Default input audio format (gradio): 48 kHz 16 bits int\n",
    "    # Default output audio format (whisper): 16 kHz 32 bits float\n",
    "    def __init__(self, max_length_sec=30, input_sampling_rate=48000, input_dtype=np.int16, output_sampling_rate=16000, output_dtype=np.float32):\n",
    "        \n",
    "        self.input_sampling_rate = input_sampling_rate\n",
    "        self.input_dtype = input_dtype\n",
    "        self.output_sampling_rate = output_sampling_rate\n",
    "        self.output_dtype = output_dtype\n",
    "\n",
    "        self.output_buffer = np.empty((0,), dtype=output_dtype)\n",
    "        self.max_buffer_length = max_length_sec * output_sampling_rate\n",
    "\n",
    "    # input_samples should be a numpy array recorded with input_sampling_rate and input_dtype\n",
    "    def append_input_samples(self, input_samples):\n",
    "\n",
    "        # Convert input sampling rate to output sampling rate\n",
    "        if self.input_sampling_rate==48000 and self.output_sampling_rate==16000:\n",
    "            input_samples = input_samples[::3]\n",
    "        elif self.input_sampling_rate!=self.output_sampling_rate:\n",
    "            raise TypeError(f\"Conversion of input sampling rate {self.input_sampling_rate} to output sampling rate {self.output_sampling_rate} is not supported\")\n",
    "        \n",
    "        # Convert input dtype to output dtype\n",
    "        if self.input_dtype==np.int16 and self.output_dtype==np.float32:\n",
    "            input_samples = input_samples.astype(np.float32)\n",
    "            max_value = np.max(np.abs(input_samples))\n",
    "            if max_value==0:\n",
    "                return\n",
    "            else:\n",
    "                input_samples /= max_value\n",
    "        elif self.input_dtype!=self.output_dtype:\n",
    "            raise TypeError(f\"Conversion of input type {self.input_type} to output type {self.output_type} is not supported\")\n",
    "\n",
    "        # Accumulate samples in the output buffer with a rolling window\n",
    "        self.output_buffer = np.concatenate((self.output_buffer, input_samples))\n",
    "        if len(self.output_buffer) > self.max_buffer_length:\n",
    "            self.output_buffer = self.output_buffer[len(self.output_buffer)-self.max_buffer_length:]\n",
    "    \n",
    "    # output buffer is a numpy array ready to be used by the transcription model\n",
    "    def get_output_samples(self):\n",
    "        return self.output_buffer\n",
    "\n",
    "    def clear(self):\n",
    "        self.output_buffer = np.empty((0,), dtype=self.output_dtype)\n",
    "\n",
    "    # Loads the output buffer from a file\n",
    "    def load(self, filename):\n",
    "        self.output_buffer = np.load(filename)\n",
    "\n",
    "    # Saves the output buffer from a file\n",
    "    def save(self, filename):\n",
    "        np.save(filename, self.output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962d4b5-e561-4eaa-ada6-3337b3721e3d",
   "metadata": {},
   "source": [
    "Load test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d64ace-a949-40e5-a88e-199077fe23f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:16.033319Z",
     "iopub.status.busy": "2024-07-10T19:26:16.033072Z",
     "iopub.status.idle": "2024-07-10T19:26:16.040902Z",
     "shell.execute_reply": "2024-07-10T19:26:16.040245Z",
     "shell.execute_reply.started": "2024-07-10T19:26:16.033299Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobuffer = RollingAudioBuffer()\n",
    "audiobuffer.load(\"test_en.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ee8be-4642-4ed2-8e18-a9529ea6e300",
   "metadata": {},
   "source": [
    "## Option 1: Huggingface automatic-speech-recognition pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5d533-b622-4b7c-9a02-7588e999d8fb",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30e428-f689-47ef-a9b2-53905fad7387",
   "metadata": {},
   "source": [
    "This dependency is necessary for whisper with Huggingface, but is not necessary for whisper with faster-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dea40c-3f32-420e-9e49-1cf613a3d2df",
   "metadata": {},
   "source": [
    "> apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb745167-5f0e-4ca1-86cc-861def45e453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:23.045358Z",
     "iopub.status.busy": "2024-07-10T19:26:23.045189Z",
     "iopub.status.idle": "2024-07-10T19:26:23.210102Z",
     "shell.execute_reply": "2024-07-10T19:26:23.209621Z",
     "shell.execute_reply.started": "2024-07-10T19:26:23.045345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "libavutil      56. 51.100 / 56. 51.100\n",
      "libavcodec     58. 91.100 / 58. 91.100\n",
      "libavformat    58. 45.100 / 58. 45.100\n",
      "libavdevice    58. 10.100 / 58. 10.100\n",
      "libavfilter     7. 85.100 /  7. 85.100\n",
      "libavresample   4.  0.  0 /  4.  0.  0\n",
      "libswscale      5.  7.100 /  5.  7.100\n",
      "libswresample   3.  7.100 /  3.  7.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dacd0d5-4f97-40f2-948c-b0f2e7545fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:25.128539Z",
     "iopub.status.busy": "2024-07-10T19:26:25.128199Z",
     "iopub.status.idle": "2024-07-10T19:26:25.133461Z",
     "shell.execute_reply": "2024-07-10T19:26:25.132638Z",
     "shell.execute_reply.started": "2024-07-10T19:26:25.128512Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37208fa3-fe1e-4255-820c-26b3a9ef5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae56fa1-92c1-49eb-b571-539616487108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:31.587898Z",
     "iopub.status.busy": "2024-07-10T19:26:31.587575Z",
     "iopub.status.idle": "2024-07-10T19:26:31.599643Z",
     "shell.execute_reply": "2024-07-10T19:26:31.598844Z",
     "shell.execute_reply.started": "2024-07-10T19:26:31.587874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.42.3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db5be-d7d2-4c80-9a9f-88c5b071426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f8c895-4fca-4cf9-b25b-45848406584b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:33.406089Z",
     "iopub.status.busy": "2024-07-10T19:26:33.405807Z",
     "iopub.status.idle": "2024-07-10T19:26:33.414484Z",
     "shell.execute_reply": "2024-07-10T19:26:33.413396Z",
     "shell.execute_reply.started": "2024-07-10T19:26:33.406069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.9.post1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('flash_attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941643f3-348c-4ab6-8cc9-0b4b2b7f1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15aa5d0e-9fa4-4626-a9b8-0a54f519f4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:34.815411Z",
     "iopub.status.busy": "2024-07-10T19:26:34.814306Z",
     "iopub.status.idle": "2024-07-10T19:26:34.822524Z",
     "shell.execute_reply": "2024-07-10T19:26:34.821477Z",
     "shell.execute_reply.started": "2024-07-10T19:26:34.815383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.32.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('accelerate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ce54d-74d3-48db-894d-2a02a082fd9c",
   "metadata": {},
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1cbc6d-3101-45f2-a3f4-0b75f47f4a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:37.592964Z",
     "iopub.status.busy": "2024-07-10T19:26:37.592678Z",
     "iopub.status.idle": "2024-07-10T19:26:46.788888Z",
     "shell.execute_reply": "2024-07-10T19:26:46.787847Z",
     "shell.execute_reply.started": "2024-07-10T19:26:37.592943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Load whisper-small in 16 bits with flash attention 2 on the GPU\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\", \n",
    "                       model_kwargs={\"torch_dtype\":torch.float16, \"attn_implementation\":\"flash_attention_2\", \"device_map\":0}, \n",
    "                       generate_kwargs = {\"task\":\"transcribe\", \"language\":\"english\"})\n",
    "\n",
    "# torch compile the model to speed up inference\n",
    "transcriber.model.model = torch.compile(transcriber.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be0b32a-df35-4fbe-8754-69420cd4c94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:26:48.656752Z",
     "iopub.status.busy": "2024-07-10T19:26:48.656285Z",
     "iopub.status.idle": "2024-07-10T19:26:48.662594Z",
     "shell.execute_reply": "2024-07-10T19:26:48.661792Z",
     "shell.execute_reply.started": "2024-07-10T19:26:48.656706Z"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_speech_to_text_hf(audiobuffer):\n",
    "    return transcriber({\"sampling_rate\": audiobuffer.output_sampling_rate, \"raw\": audiobuffer.output_buffer})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5773f50-3d76-4bb2-8698-6e2ea392f414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:27:54.440389Z",
     "iopub.status.busy": "2024-07-10T19:27:54.440093Z",
     "iopub.status.idle": "2024-07-10T19:27:56.914645Z",
     "shell.execute_reply": "2024-07-10T19:27:56.914010Z",
     "shell.execute_reply.started": "2024-07-10T19:27:54.440367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà! You didn't find it? Yeah!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_speech_to_text_hf(audiobuffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9f9bc-3612-4505-92e5-bee06c2ce2a8",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d42864-f44e-4048-a86d-af2d34baa7df",
   "metadata": {},
   "source": [
    "whisper-small\n",
    "- basic huggingface pipeline: 5.92 sec\n",
    "- with 16 bits & flash attention: 2.42 sec\n",
    "- and with torch.compile: 2.25 sec\n",
    "- laptop plugged: 1.07 sec\n",
    "- divide sampling rate by 3: 800-900 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeabad2-a4c7-468d-a868-4b51696278df",
   "metadata": {},
   "source": [
    "## Option 2: Systran faster-whisper with ctranslate2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b4eae-5990-4116-a281-ed7baddd1d41",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "131f1076-1603-4d7f-8928-da2bbfee9fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:44:40.326771Z",
     "iopub.status.busy": "2024-07-06T13:44:40.326337Z",
     "iopub.status.idle": "2024-07-06T13:44:40.329433Z",
     "shell.execute_reply": "2024-07-06T13:44:40.328784Z",
     "shell.execute_reply.started": "2024-07-06T13:44:40.326755Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca0b5f-b574-404c-b009-eb8e91371002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4346287e-57e4-4728-befc-f10b9d85aff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:28:46.135920Z",
     "iopub.status.busy": "2024-07-10T19:28:46.135689Z",
     "iopub.status.idle": "2024-07-10T19:28:46.141760Z",
     "shell.execute_reply": "2024-07-10T19:28:46.141147Z",
     "shell.execute_reply.started": "2024-07-10T19:28:46.135907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('faster-whisper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628ac67-932c-4796-b43f-53ba77946988",
   "metadata": {},
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781d5c0d-5701-49ed-95d3-d736f8696f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:28:49.094041Z",
     "iopub.status.busy": "2024-07-10T19:28:49.093603Z",
     "iopub.status.idle": "2024-07-10T19:28:50.882588Z",
     "shell.execute_reply": "2024-07-10T19:28:50.882047Z",
     "shell.execute_reply.started": "2024-07-10T19:28:49.094008Z"
    }
   },
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Directly load an optimized model in 16 bits on the GPU\n",
    "whispermodel = WhisperModel(\"small\", device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a1ab9c-9321-43e9-a2a4-de6f7f71705b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:28:51.370437Z",
     "iopub.status.busy": "2024-07-10T19:28:51.370192Z",
     "iopub.status.idle": "2024-07-10T19:28:51.374695Z",
     "shell.execute_reply": "2024-07-10T19:28:51.373917Z",
     "shell.execute_reply.started": "2024-07-10T19:28:51.370417Z"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_speech_to_text_fw(audiobuffer):\n",
    "    segments, info = whispermodel.transcribe(audiobuffer.output_buffer, beam_size=5, language=\"en\", condition_on_previous_text=False, vad_filter=True, vad_parameters=dict(min_silence_duration_ms=500))\n",
    "    return \"\".join([segment.text for segment in segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff72f64-ff57-4022-a5d6-31d115c100ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:29:13.815149Z",
     "iopub.status.busy": "2024-07-10T19:29:13.814840Z",
     "iopub.status.idle": "2024-07-10T19:29:18.315560Z",
     "shell.execute_reply": "2024-07-10T19:29:18.315009Z",
     "shell.execute_reply.started": "2024-07-10T19:29:13.815130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' So, I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic. and did you find it? yeah'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_speech_to_text_fw(audiobuffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f773c4-672b-4121-bd0d-b0bd0ef7eddb",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a08729-62e6-454b-88de-e7273bf599f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T13:47:13.827690Z",
     "iopub.status.busy": "2024-07-06T13:47:13.827044Z",
     "iopub.status.idle": "2024-07-06T13:47:13.831857Z",
     "shell.execute_reply": "2024-07-06T13:47:13.831224Z",
     "shell.execute_reply.started": "2024-07-06T13:47:13.827666Z"
    }
   },
   "source": [
    "whisper-small\n",
    "- 618 ms\n",
    "\n",
    "Model sizes: Huggingface default perf vs faster-whisper optimized perf (unplugged) \n",
    "- distill-large-v3 : english only, 1.5GB, 750 ms\n",
    "- \"tiny\": 20 sec -> 1.24 sec - too many errors\n",
    "- \"base\": 20 sec -> 1.72 sec vs 3 sec with huggingface\n",
    "- \"small\": 20 sec -> 4.18 sec\n",
    "- \"large-v3\": 20 sec -> 16.33 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ac740-dda6-46ad-aa48-8646b3bb6e93",
   "metadata": {},
   "source": [
    "## Translation with Helsinki-NLP/opus-mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd131d-2ffb-46cb-a3d2-8966c6f9087a",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3058dc-6d2e-4a94-ab23-87a11c3896d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:10:11.034155Z",
     "iopub.status.busy": "2024-07-06T14:10:11.033883Z",
     "iopub.status.idle": "2024-07-06T14:10:11.037264Z",
     "shell.execute_reply": "2024-07-06T14:10:11.036740Z",
     "shell.execute_reply.started": "2024-07-06T14:10:11.034137Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd8f64-8bfe-47a2-90ce-122cac596eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8613669-d990-4245-993b-0f1193b7d08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:29:58.346789Z",
     "iopub.status.busy": "2024-07-10T19:29:58.346491Z",
     "iopub.status.idle": "2024-07-10T19:29:58.353760Z",
     "shell.execute_reply": "2024-07-10T19:29:58.353222Z",
     "shell.execute_reply.started": "2024-07-10T19:29:58.346770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sentencepiece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cceb8b9-0d53-4e16-a8e0-9cb2d5a4e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61ad5a5-8fa8-4035-a0c3-22482e1d6d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:30:00.308534Z",
     "iopub.status.busy": "2024-07-10T19:30:00.308207Z",
     "iopub.status.idle": "2024-07-10T19:30:00.314183Z",
     "shell.execute_reply": "2024-07-10T19:30:00.313398Z",
     "shell.execute_reply.started": "2024-07-10T19:30:00.308513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sacremoses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061aaf1-8b7c-4d74-905c-5f672adfe0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:08:42.010912Z",
     "iopub.status.busy": "2024-07-06T14:08:42.010537Z",
     "iopub.status.idle": "2024-07-06T14:08:42.016888Z",
     "shell.execute_reply": "2024-07-06T14:08:42.015642Z",
     "shell.execute_reply.started": "2024-07-06T14:08:42.010887Z"
    }
   },
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "525f99ea-d9bf-4e75-964e-1314cb55716d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:30:02.872466Z",
     "iopub.status.busy": "2024-07-10T19:30:02.871391Z",
     "iopub.status.idle": "2024-07-10T19:30:04.882397Z",
     "shell.execute_reply": "2024-07-10T19:30:04.881661Z",
     "shell.execute_reply.started": "2024-07-10T19:30:02.872442Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "opusmtmodel = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Note: unfortunately, MarianMTModel doesn't support flash attention yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91ca64d0-2d06-466a-a10b-68d76a91846f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:30:04.883549Z",
     "iopub.status.busy": "2024-07-10T19:30:04.883382Z",
     "iopub.status.idle": "2024-07-10T19:30:04.886685Z",
     "shell.execute_reply": "2024-07-10T19:30:04.886107Z",
     "shell.execute_reply.started": "2024-07-10T19:30:04.883538Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = opusmtmodel.generate(**encoded)\n",
    "    decoded = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88a1087c-d086-4315-b41a-27c284dc11d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:30:05.779561Z",
     "iopub.status.busy": "2024-07-10T19:30:05.779266Z",
     "iopub.status.idle": "2024-07-10T19:30:06.390346Z",
     "shell.execute_reply": "2024-07-10T19:30:06.389600Z",
     "shell.execute_reply.started": "2024-07-10T19:30:05.779541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Donc, je suis sur un site Web pour essayer de trouver un emploi et j'ai dû répondre à certaines questions et j'ai dû dire ce que j'étudiais et j'ai eu quelques difficultés à trouver le bon sujet. et avez-vous trouvé?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" So, I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic. and did you find it? yeah\"\n",
    "translate_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fcea3-1c70-40c9-9cd6-6bc88b940153",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaac3ad-6919-44d5-a0a2-89510a9a8485",
   "metadata": {},
   "source": [
    "opus-mt-en-fr\n",
    "- 592 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee27a8d-e3f0-4694-9b22-d44bf31dbb84",
   "metadata": {},
   "source": [
    "## Gradio speech transcription UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea6f7f-4f58-4b1f-9245-5594f5c1001d",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acb2ef-2b38-4149-85ab-eac5f566c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad4380ce-3f9a-4bd7-be08-f04eae90edcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:30:14.141803Z",
     "iopub.status.busy": "2024-07-10T19:30:14.140859Z",
     "iopub.status.idle": "2024-07-10T19:30:14.148091Z",
     "shell.execute_reply": "2024-07-10T19:30:14.147522Z",
     "shell.execute_reply.started": "2024-07-10T19:30:14.141777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.37.2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('gradio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6af53-d400-45af-b45b-22184ec6cfb5",
   "metadata": {},
   "source": [
    "### Define audio processing function and build the associated UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb05c335-ea89-4a7a-9407-d7ab2da5f369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T20:59:18.005094Z",
     "iopub.status.busy": "2024-07-10T20:59:18.004583Z",
     "iopub.status.idle": "2024-07-10T20:59:18.014964Z",
     "shell.execute_reply": "2024-07-10T20:59:18.013680Z",
     "shell.execute_reply.started": "2024-07-10T20:59:18.005065Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Single user application => simplify the implementation with a global audio buffer\n",
    "audiobuffer = RollingAudioBuffer()\n",
    "\n",
    "# Input: tuple (sampling_rate,input_samples) received from gr.Audio component, audio_samples format is 48 kHz mono 16 bits integers\n",
    "# The input_samples are converted and added to the global audio buffer, which is then transcribed to text and translated \n",
    "# Output: tuple (english_text, french_text) transcribed and translated from the global audio buffer\n",
    "def process_audio(gradio_audio):\n",
    "    start_time = time.time()\n",
    "    sampling_date, input_samples = gradio_audio\n",
    "    audiobuffer.append_input_samples(input_samples)\n",
    "    english_text = transcribe_speech_to_text_fw(audiobuffer)\n",
    "    if len(english_text)>3:\n",
    "        french_text = translate_text(english_text)\n",
    "    else:\n",
    "        french_text = \"\"\n",
    "    end_time = time.time()\n",
    "    refresh_rate = f\"{end_time-start_time:.2f} sec\"\n",
    "    return english_text, french_text, refresh_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633498d7-fdf3-4ea2-a971-9ac004d3d52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d850b969-eb71-48b3-b4f7-195abf2feb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T21:00:03.451417Z",
     "iopub.status.busy": "2024-07-10T21:00:03.451082Z",
     "iopub.status.idle": "2024-07-10T21:00:03.523643Z",
     "shell.execute_reply": "2024-07-10T21:00:03.523067Z",
     "shell.execute_reply.started": "2024-07-10T21:00:03.451395Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def on_clear():\n",
    "    audiobuffer.clear()\n",
    "    return (\"\", \"\", \"\")\n",
    "\n",
    "# Define custom CSS\n",
    "custom_css = \"\"\"\n",
    "    #english_transcription textarea, #french_translation textarea {\n",
    "        font-size: 20px !important;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio Blocks interface\n",
    "with gr.Blocks(css=custom_css) as interface:\n",
    "    gr.Markdown(\"# Crédit Mutuel - IBM supervision committee\")\n",
    "    gr.Markdown(\"This application transcribes your english speech in real-time and translates it to French.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(sources=[\"microphone\"], streaming=True, scale=5)\n",
    "        clear_button = gr.Button(\"Clear\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        english_output = gr.Textbox(label=\"Transcription (English)\", lines=10, elem_id=\"english_transcription\")\n",
    "        french_output = gr.Textbox(label=\"Translation (French)\", lines=10, elem_id=\"french_translation\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        refresh_rate = gr.Textbox(label=\"Refresh rate\")\n",
    "    \n",
    "    clear_button.click(fn=on_clear, inputs=None, outputs=[english_output, french_output, refresh_rate])\n",
    "    \n",
    "    audio_input.stream(process_audio, inputs=audio_input, outputs=[english_output, french_output, refresh_rate]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4bbca-cf57-4ba1-9450-196fa517d5d1",
   "metadata": {},
   "source": [
    "### Display and stop the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8161760-b628-48c3-bb9e-1c8e90a94fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T21:00:04.245866Z",
     "iopub.status.busy": "2024-07-10T21:00:04.245658Z",
     "iopub.status.idle": "2024-07-10T21:00:04.296749Z",
     "shell.execute_reply": "2024-07-10T21:00:04.296242Z",
     "shell.execute_reply.started": "2024-07-10T21:00:04.245853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34740e6d-dbf2-47ed-8108-9e33ce750739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T20:59:22.196414Z",
     "iopub.status.busy": "2024-07-10T20:59:22.196105Z",
     "iopub.status.idle": "2024-07-10T20:59:22.374774Z",
     "shell.execute_reply": "2024-07-10T20:59:22.373601Z",
     "shell.execute_reply.started": "2024-07-10T20:59:22.196397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7863\n"
     ]
    }
   ],
   "source": [
    "interface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069290c-616e-401b-b761-ff3f53c250b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiobuffer.save(\"last_speech_en.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
