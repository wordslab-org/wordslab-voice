{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b30e428-f689-47ef-a9b2-53905fad7387",
   "metadata": {},
   "source": [
    "This dependency is necessary for whisper with Huggingface, but is not necessary for whisper with faster-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dea40c-3f32-420e-9e49-1cf613a3d2df",
   "metadata": {},
   "source": [
    "> apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dacd0d5-4f97-40f2-948c-b0f2e7545fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T16:00:07.626560Z",
     "iopub.status.busy": "2024-06-29T16:00:07.626243Z",
     "iopub.status.idle": "2024-06-29T16:00:07.631799Z",
     "shell.execute_reply": "2024-06-29T16:00:07.630621Z",
     "shell.execute_reply.started": "2024-06-29T16:00:07.626535Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acb2ef-2b38-4149-85ab-eac5f566c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4380ce-3f9a-4bd7-be08-f04eae90edcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T19:54:36.680822Z",
     "iopub.status.busy": "2024-06-28T19:54:36.680509Z",
     "iopub.status.idle": "2024-06-28T19:54:36.692520Z",
     "shell.execute_reply": "2024-06-28T19:54:36.691542Z",
     "shell.execute_reply.started": "2024-06-28T19:54:36.680800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.37.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37208fa3-fe1e-4255-820c-26b3a9ef5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae56fa1-92c1-49eb-b571-539616487108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T19:55:09.440272Z",
     "iopub.status.busy": "2024-06-28T19:55:09.439899Z",
     "iopub.status.idle": "2024-06-28T19:55:09.451993Z",
     "shell.execute_reply": "2024-06-28T19:55:09.450948Z",
     "shell.execute_reply.started": "2024-06-28T19:55:09.440240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.42.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1cbc6d-3101-45f2-a3f4-0b75f47f4a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:57.021167Z",
     "iopub.status.busy": "2024-07-06T12:48:57.020213Z",
     "iopub.status.idle": "2024-07-06T12:49:03.594553Z",
     "shell.execute_reply": "2024-07-06T12:49:03.593802Z",
     "shell.execute_reply.started": "2024-07-06T12:48:57.021117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\", model_kwargs={}, generate_kwargs = {\"task\":\"transcribe\", \"language\":\"english\"}, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52b623-cb97-4732-aa69-a39542acedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "transcriber.model.model = torch.compile(transcriber.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361a44fe-2040-417f-89de-5b389612067e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:04.143861Z",
     "iopub.status.busy": "2024-07-06T12:50:04.143495Z",
     "iopub.status.idle": "2024-07-06T12:50:04.150596Z",
     "shell.execute_reply": "2024-07-06T12:50:04.149418Z",
     "shell.execute_reply.started": "2024-07-06T12:50:04.143838Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class RollingAudioBuffer:\n",
    "    def __init__(self, max_length_sec, sampling_rate):\n",
    "        self.buffer = np.empty((0,), dtype=np.float32)\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.max_length = max_length_sec * sampling_rate\n",
    "\n",
    "    def add_samples(self, np_samples):\n",
    "        self.buffer = np.concatenate((self.buffer, np_samples))\n",
    "        if len(self.buffer) > self.max_length:\n",
    "            self.buffer = self.buffer[len(self.buffer)-self.max_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42285c4e-c3bc-4fb9-bf01-c9d6ab1312a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "audiobuffer = RollingAudioBuffer(max_length_sec=25, sampling_rate=48000)\n",
    "\n",
    "def transcribe(audio):\n",
    "    # Get audio stream from gr.Audio component: int16\n",
    "    sampling_rate, np_samples = audio\n",
    "    print(sampling_rate, np_samples.shape)\n",
    "\n",
    "    # Convert audio stream to whisper format: fp32 between -1 and 1\n",
    "    np_samples = np_samples.astype(np.float32)\n",
    "    np_samples /= np.max(np.abs(np_samples))\n",
    "\n",
    "    # Accumulate audio samples in buffer\n",
    "    audiobuffer.add_samples(np_samples)\n",
    "    \n",
    "    # Convert audio stream to text\n",
    "    start_time = time.time()\n",
    "    text = transcriber({\"sampling_rate\": sampling_rate, \"raw\": audiobuffer.buffer})[\"text\"]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Transcription executed in {elapsed_time*1000:.2f} ms\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\"], streaming=True),\n",
    "    \"text\",\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0fd47-9fd6-4647-87cc-66e7bd148e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"julie_en.npy\", audiobuffer.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eab84a8-0a74-4af6-9043-8e87200b80e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:12.693793Z",
     "iopub.status.busy": "2024-07-06T12:50:12.693418Z",
     "iopub.status.idle": "2024-07-06T12:50:12.698922Z",
     "shell.execute_reply": "2024-07-06T12:50:12.697998Z",
     "shell.execute_reply.started": "2024-07-06T12:50:12.693769Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobuffer = RollingAudioBuffer(max_length_sec=25, sampling_rate=48000)\n",
    "audiobuffer.buffer = np.load(\"julie_en.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5773f50-3d76-4bb2-8698-6e2ea392f414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:51:18.079354Z",
     "iopub.status.busy": "2024-07-06T12:51:18.078921Z",
     "iopub.status.idle": "2024-07-06T12:51:22.953446Z",
     "shell.execute_reply": "2024-07-06T12:51:22.952926Z",
     "shell.execute_reply.started": "2024-07-06T12:51:18.079320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà. Y'a trouvé pas? Ouais, j'ai\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber({\"sampling_rate\": audiobuffer.sampling_rate, \"raw\": audiobuffer.buffer})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca0b5f-b574-404c-b009-eb8e91371002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4346287e-57e4-4728-befc-f10b9d85aff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T16:00:29.385255Z",
     "iopub.status.busy": "2024-06-29T16:00:29.384232Z",
     "iopub.status.idle": "2024-06-29T16:00:29.394359Z",
     "shell.execute_reply": "2024-06-29T16:00:29.393757Z",
     "shell.execute_reply.started": "2024-06-29T16:00:29.385208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('faster-whisper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2950c49f-b762-4f77-a169-ee2b05139d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T16:37:49.724262Z",
     "iopub.status.busy": "2024-06-29T16:37:49.723791Z",
     "iopub.status.idle": "2024-06-29T16:37:49.732590Z",
     "shell.execute_reply": "2024-06-29T16:37:49.731586Z",
     "shell.execute_reply.started": "2024-06-29T16:37:49.724229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220800,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audiobuffer.buffer[::4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbfca2c0-40b9-4a50-b96f-e71ec1c7eeb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:02:29.904125Z",
     "iopub.status.busy": "2024-06-29T17:02:29.903749Z",
     "iopub.status.idle": "2024-06-29T17:02:32.896753Z",
     "shell.execute_reply": "2024-06-29T17:02:32.896043Z",
     "shell.execute_reply.started": "2024-06-29T17:02:29.904103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Le 30 juin et le 7 juillet prochain se tiendra dans notre circonscription et partout en France une nouvelle élection législative. J'y suis candidat. Depuis 7 ans, j'ai défendu à l'assandé nationale des positions forgées par mes convictions et par nos échanges que j'ai toujours voulu constant et nombreux.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber({\"sampling_rate\": audiobuffer.sampling_rate/4, \"raw\": audiobuffer.buffer[::4]})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781d5c0d-5701-49ed-95d3-d736f8696f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:12:53.826764Z",
     "iopub.status.busy": "2024-06-29T17:12:53.826226Z",
     "iopub.status.idle": "2024-06-29T17:12:58.716200Z",
     "shell.execute_reply": "2024-06-29T17:12:58.715324Z",
     "shell.execute_reply.started": "2024-06-29T17:12:53.826731Z"
    }
   },
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# distill-large-v3 : english only, 1.5GB, 750 ms\n",
    "\n",
    "# model_size = \"tiny\" # 20 sec -> 1.24 sec - too many errors\n",
    "# model_size = \"base\" # 20 sec -> 1.72 sec vs 3 sec with huggingface\n",
    "# model_size = \"small\" # 20 sec -> 4.18 sec\n",
    "# model_size = \"large-v3\" # 20 sec -> 16.33 sec\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aff72f64-ff57-4022-a5d6-31d115c100ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T17:13:00.979868Z",
     "iopub.status.busy": "2024-06-29T17:13:00.979388Z",
     "iopub.status.idle": "2024-06-29T17:13:17.309262Z",
     "shell.execute_reply": "2024-06-29T17:13:17.308752Z",
     "shell.execute_reply.started": "2024-06-29T17:13:00.979850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 6.64s]  Cher monsieur, le 30 juin et le 7 juillet prochains se tiendra dans notre circonscription et partout en France une nouvelle élection législative.\n",
      "[7.22s -> 7.98s]  J'y suis candidat.\n",
      "[8.50s -> 14.26s]  Depuis 7 ans, j'ai défendu à l'Assemblée nationale des positions forgées par mes convictions et par nos échanges que j'ai toujours voulu constants et nombreux.\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(audiobuffer.buffer[::4], beam_size=5, language=\"fr\", condition_on_previous_text=False, vad_filter=True, vad_parameters=dict(min_silence_duration_ms=500))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ecd8f64-8bfe-47a2-90ce-122cac596eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:29:47.718889Z",
     "iopub.status.busy": "2024-07-06T12:29:47.718471Z",
     "iopub.status.idle": "2024-07-06T12:29:50.165698Z",
     "shell.execute_reply": "2024-07-06T12:29:50.164995Z",
     "shell.execute_reply.started": "2024-07-06T12:29:47.718852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525f99ea-d9bf-4e75-964e-1314cb55716d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:32:16.190869Z",
     "iopub.status.busy": "2024-07-06T12:32:16.189441Z",
     "iopub.status.idle": "2024-07-06T12:32:18.335801Z",
     "shell.execute_reply": "2024-07-06T12:32:18.334840Z",
     "shell.execute_reply.started": "2024-07-06T12:32:16.190845Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Prepare the input text\n",
    "def translate_texts(src_texts):\n",
    "    encoded = tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Perform the translation\n",
    "    translated = model.generate(**encoded)\n",
    "    tgt_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "    return tgt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a1087c-d086-4315-b41a-27c284dc11d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:33:05.071006Z",
     "iopub.status.busy": "2024-07-06T12:33:05.070725Z",
     "iopub.status.idle": "2024-07-06T12:33:06.795686Z",
     "shell.execute_reply": "2024-07-06T12:33:06.794745Z",
     "shell.execute_reply.started": "2024-07-06T12:33:05.070989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The result is a distilled model that performs to within 1% WER of large-v3 on long-form audio using both the sequential and chunked algorithms, and outperforms distil-large-v2 by 4.8% using the sequential algorithm. The model is also faster than previous Distil-Whisper models: 6.3x faster than large-v3, and 1.1x faster than distil-large-v2.\n",
      "Translated: Le résultat est un modèle distillé qui effectue à moins de 1% WER de grand-v3 sur l'audio de forme longue en utilisant à la fois les algorithmes séquentielle et coupé, et surperforms distil-large-v2 de 4,8 % en utilisant l'algorithme séquentielle. Le modèle est également plus rapide que les modèles Distil-Whisper précédents: 6,3x plus rapide que grand-v3 et 1,1x plus rapide que distil-large-v2.\n"
     ]
    }
   ],
   "source": [
    "# Test the translations\n",
    "src_texts = [\"The result is a distilled model that performs to within 1% WER of large-v3 on long-form audio using both the sequential and chunked algorithms, and outperforms distil-large-v2 by 4.8% using the sequential algorithm. The model is also faster than previous Distil-Whisper models: 6.3x faster than large-v3, and 1.1x faster than distil-large-v2.\"]\n",
    "tgt_texts = translate_texts(src_texts)\n",
    "\n",
    "for src, tgt in zip(src_texts, tgt_texts):\n",
    "    print(f\"Source: {src}\")\n",
    "    print(f\"Translated: {tgt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e7408-2290-4892-b84c-a0f8470c4ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
