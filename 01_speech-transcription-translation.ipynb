{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd66fbdb-5fed-4b9f-9f76-8351102f616d",
   "metadata": {},
   "source": [
    "# Real-time speech transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968adba8-b4dc-4541-b5ba-339a8e8af1bd",
   "metadata": {},
   "source": [
    "## Audio buffer management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0269d88-e7f0-4d57-820d-af5403281b65",
   "metadata": {},
   "source": [
    "The audio samples for real-time speech transcription will be accumulated in a rolling audio buffer with a limited duration (< 30 sec for whsiper).\n",
    "\n",
    "You don't need to understand the code below, you can just execute the cell to use the class in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05032d8f-2cfe-4538-9196-fc498c837bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:34.725312Z",
     "iopub.status.busy": "2025-11-08T13:24:34.725212Z",
     "iopub.status.idle": "2025-11-08T13:24:34.849764Z",
     "shell.execute_reply": "2025-11-08T13:24:34.849303Z",
     "shell.execute_reply.started": "2025-11-08T13:24:34.725304Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 1. Aggregates audio samples in a buffer and keeps only the last max_length_sec seconds.\n",
    "# 2. Converts the audio format from input to output sampling rate and dtype.\n",
    "class RollingAudioBuffer:\n",
    "\n",
    "    # Default max length (whisper): 30 sec\n",
    "    # Default input audio format (gradio): 48 kHz 16 bits int\n",
    "    # Default output audio format (whisper): 16 kHz 32 bits float\n",
    "    def __init__(self, max_length_sec=30, input_sampling_rate=48000, input_dtype=np.int16, output_sampling_rate=16000, output_dtype=np.float32):\n",
    "        \n",
    "        self.input_sampling_rate = input_sampling_rate\n",
    "        self.input_dtype = input_dtype\n",
    "        self.output_sampling_rate = output_sampling_rate\n",
    "        self.output_dtype = output_dtype\n",
    "\n",
    "        self.output_buffer = np.empty((0,), dtype=output_dtype)\n",
    "        self.max_buffer_length = max_length_sec * output_sampling_rate\n",
    "\n",
    "    # input_samples should be a numpy array recorded with input_sampling_rate and input_dtype\n",
    "    def append_input_samples(self, input_samples):\n",
    "\n",
    "        # Convert input sampling rate to output sampling rate\n",
    "        if self.input_sampling_rate==48000 and self.output_sampling_rate==16000:\n",
    "            input_samples = input_samples[::3]\n",
    "        elif self.input_sampling_rate!=self.output_sampling_rate:\n",
    "            raise TypeError(f\"Conversion of input sampling rate {self.input_sampling_rate} to output sampling rate {self.output_sampling_rate} is not supported\")\n",
    "        \n",
    "        # Convert input dtype to output dtype\n",
    "        if self.input_dtype==np.int16 and self.output_dtype==np.float32:\n",
    "            input_samples = input_samples.astype(np.float32)\n",
    "            max_value = np.max(np.abs(input_samples))\n",
    "            if max_value==0:\n",
    "                return\n",
    "            else:\n",
    "                input_samples /= max_value\n",
    "        elif self.input_dtype!=self.output_dtype:\n",
    "            raise TypeError(f\"Conversion of input type {self.input_type} to output type {self.output_type} is not supported\")\n",
    "\n",
    "        # Accumulate samples in the output buffer with a rolling window\n",
    "        self.output_buffer = np.concatenate((self.output_buffer, input_samples))\n",
    "        if len(self.output_buffer) > self.max_buffer_length:\n",
    "            self.output_buffer = self.output_buffer[len(self.output_buffer)-self.max_buffer_length:]\n",
    "    \n",
    "    # output buffer is a numpy array ready to be used by the transcription model\n",
    "    def get_output_samples(self):\n",
    "        return self.output_buffer\n",
    "\n",
    "    def clear(self):\n",
    "        self.output_buffer = np.empty((0,), dtype=self.output_dtype)\n",
    "\n",
    "    # Loads the output buffer from a file\n",
    "    def load(self, filename):\n",
    "        self.output_buffer = np.load(filename)\n",
    "\n",
    "    # Saves the output buffer from a file\n",
    "    def save(self, filename):\n",
    "        np.save(filename, self.output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962d4b5-e561-4eaa-ada6-3337b3721e3d",
   "metadata": {},
   "source": [
    "Load test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d64ace-a949-40e5-a88e-199077fe23f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:34.850183Z",
     "iopub.status.busy": "2025-11-08T13:24:34.850072Z",
     "iopub.status.idle": "2025-11-08T13:24:34.853828Z",
     "shell.execute_reply": "2025-11-08T13:24:34.853459Z",
     "shell.execute_reply.started": "2025-11-08T13:24:34.850175Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobuffer = RollingAudioBuffer()\n",
    "audiobuffer.load(\"data/test_audio_en.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ee8be-4642-4ed2-8e18-a9529ea6e300",
   "metadata": {},
   "source": [
    "## Huggingface automatic-speech-recognition pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5d533-b622-4b7c-9a02-7588e999d8fb",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb745167-5f0e-4ca1-86cc-861def45e453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:35.998548Z",
     "iopub.status.busy": "2025-11-08T13:24:35.998370Z",
     "iopub.status.idle": "2025-11-08T13:24:36.307954Z",
     "shell.execute_reply": "2025-11-08T13:24:36.307193Z",
     "shell.execute_reply.started": "2025-11-08T13:24:35.998538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "libavutil      58. 29.100 / 58. 29.100\n",
      "libavcodec     60. 31.102 / 60. 31.102\n",
      "libavformat    60. 16.100 / 60. 16.100\n",
      "libavdevice    60.  3.100 / 60.  3.100\n",
      "libavfilter     9. 12.100 /  9. 12.100\n",
      "libswscale      7.  5.100 /  7.  5.100\n",
      "libswresample   4. 12.100 /  4. 12.100\n",
      "libpostproc    57.  3.100 / 57.  3.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37208fa3-fe1e-4255-820c-26b3a9ef5d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:36.559616Z",
     "iopub.status.busy": "2025-11-08T13:24:36.559449Z",
     "iopub.status.idle": "2025-11-08T13:24:36.816708Z",
     "shell.execute_reply": "2025-11-08T13:24:36.815750Z",
     "shell.execute_reply.started": "2025-11-08T13:24:36.559605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/home/jupyterlab/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m275 packages\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m178 packages\u001b[0m \u001b[2min 58ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dacd0d5-4f97-40f2-948c-b0f2e7545fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:36.837877Z",
     "iopub.status.busy": "2025-11-08T13:24:36.837684Z",
     "iopub.status.idle": "2025-11-08T13:24:36.840404Z",
     "shell.execute_reply": "2025-11-08T13:24:36.839829Z",
     "shell.execute_reply.started": "2025-11-08T13:24:36.837864Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae56fa1-92c1-49eb-b571-539616487108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:37.190962Z",
     "iopub.status.busy": "2025-11-08T13:24:37.190810Z",
     "iopub.status.idle": "2025-11-08T13:24:37.197611Z",
     "shell.execute_reply": "2025-11-08T13:24:37.197113Z",
     "shell.execute_reply.started": "2025-11-08T13:24:37.190954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.57.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15aa5d0e-9fa4-4626-a9b8-0a54f519f4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:37.662741Z",
     "iopub.status.busy": "2025-11-08T13:24:37.662237Z",
     "iopub.status.idle": "2025-11-08T13:24:37.683731Z",
     "shell.execute_reply": "2025-11-08T13:24:37.683255Z",
     "shell.execute_reply.started": "2025-11-08T13:24:37.662713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('accelerate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ce54d-74d3-48db-894d-2a02a082fd9c",
   "metadata": {},
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1cbc6d-3101-45f2-a3f4-0b75f47f4a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:54.840705Z",
     "iopub.status.busy": "2025-11-08T13:24:54.839853Z",
     "iopub.status.idle": "2025-11-08T13:24:56.560968Z",
     "shell.execute_reply": "2025-11-08T13:24:56.560524Z",
     "shell.execute_reply.started": "2025-11-08T13:24:54.840665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Load whisper-small in 16 bits with flash attention 2 on the GPU\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\", \n",
    "                       model_kwargs={\"dtype\":torch.float16, \"attn_implementation\":\"sdpa\", \"device_map\":0}, \n",
    "                       generate_kwargs = {\"task\":\"transcribe\", \"language\":\"english\"})\n",
    "\n",
    "# torch compile the model to speed up inference\n",
    "transcriber.model.model = torch.compile(transcriber.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be0b32a-df35-4fbe-8754-69420cd4c94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:24:56.561515Z",
     "iopub.status.busy": "2025-11-08T13:24:56.561418Z",
     "iopub.status.idle": "2025-11-08T13:24:56.567434Z",
     "shell.execute_reply": "2025-11-08T13:24:56.567063Z",
     "shell.execute_reply.started": "2025-11-08T13:24:56.561507Z"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_speech_to_text_hf(audiobuffer):\n",
    "    return transcriber({\"sampling_rate\": audiobuffer.output_sampling_rate, \"raw\": audiobuffer.output_buffer})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d0bfbc-7fc4-4eb5-b44e-31cf50d75518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:12.552726Z",
     "iopub.status.busy": "2025-11-08T13:25:12.552361Z",
     "iopub.status.idle": "2025-11-08T13:25:13.174475Z",
     "shell.execute_reply": "2025-11-08T13:25:13.174089Z",
     "shell.execute_reply.started": "2025-11-08T13:25:12.552712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà! You didn't find it? Yeah!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_speech_to_text_hf(audiobuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5773f50-3d76-4bb2-8698-6e2ea392f414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:14.535308Z",
     "iopub.status.busy": "2025-11-08T13:25:14.534836Z",
     "iopub.status.idle": "2025-11-08T13:25:18.017320Z",
     "shell.execute_reply": "2025-11-08T13:25:18.016939Z",
     "shell.execute_reply.started": "2025-11-08T13:25:14.535278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428 ms ± 35 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit transcribe_speech_to_text_hf(audiobuffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9f9bc-3612-4505-92e5-bee06c2ce2a8",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d42864-f44e-4048-a86d-af2d34baa7df",
   "metadata": {},
   "source": [
    "whisper-small on RTX 4090 -> 435 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ac740-dda6-46ad-aa48-8646b3bb6e93",
   "metadata": {},
   "source": [
    "## Translation with Helsinki-NLP/opus-mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd131d-2ffb-46cb-a3d2-8966c6f9087a",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ecd8f64-8bfe-47a2-90ce-122cac596eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:22.762727Z",
     "iopub.status.busy": "2025-11-08T13:25:22.762552Z",
     "iopub.status.idle": "2025-11-08T13:25:22.916608Z",
     "shell.execute_reply": "2025-11-08T13:25:22.915659Z",
     "shell.execute_reply.started": "2025-11-08T13:25:22.762718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/home/jupyterlab/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m275 packages\u001b[0m \u001b[2min 0.87ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m178 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8613669-d990-4245-993b-0f1193b7d08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:23.314630Z",
     "iopub.status.busy": "2025-11-08T13:25:23.314423Z",
     "iopub.status.idle": "2025-11-08T13:25:23.319423Z",
     "shell.execute_reply": "2025-11-08T13:25:23.319096Z",
     "shell.execute_reply.started": "2025-11-08T13:25:23.314618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sentencepiece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c61ad5a5-8fa8-4035-a0c3-22482e1d6d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:23.772384Z",
     "iopub.status.busy": "2025-11-08T13:25:23.771928Z",
     "iopub.status.idle": "2025-11-08T13:25:23.780631Z",
     "shell.execute_reply": "2025-11-08T13:25:23.779766Z",
     "shell.execute_reply.started": "2025-11-08T13:25:23.772355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sacremoses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061aaf1-8b7c-4d74-905c-5f672adfe0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:08:42.010912Z",
     "iopub.status.busy": "2024-07-06T14:08:42.010537Z",
     "iopub.status.idle": "2024-07-06T14:08:42.016888Z",
     "shell.execute_reply": "2024-07-06T14:08:42.015642Z",
     "shell.execute_reply.started": "2024-07-06T14:08:42.010887Z"
    }
   },
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "525f99ea-d9bf-4e75-964e-1314cb55716d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:24.867685Z",
     "iopub.status.busy": "2025-11-08T13:25:24.867207Z",
     "iopub.status.idle": "2025-11-08T13:25:26.742285Z",
     "shell.execute_reply": "2025-11-08T13:25:26.741806Z",
     "shell.execute_reply.started": "2025-11-08T13:25:24.867654Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "opusmtmodel = MarianMTModel.from_pretrained(model_name, attn_implementation=\"sdpa\", device_map=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ca64d0-2d06-466a-a10b-68d76a91846f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:28.243925Z",
     "iopub.status.busy": "2025-11-08T13:25:28.243653Z",
     "iopub.status.idle": "2025-11-08T13:25:28.248190Z",
     "shell.execute_reply": "2025-11-08T13:25:28.247614Z",
     "shell.execute_reply.started": "2025-11-08T13:25:28.243908Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "    translated = opusmtmodel.generate(**encoded)\n",
    "    decoded = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a1087c-d086-4315-b41a-27c284dc11d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:28.997418Z",
     "iopub.status.busy": "2025-11-08T13:25:28.997224Z",
     "iopub.status.idle": "2025-11-08T13:25:29.911844Z",
     "shell.execute_reply": "2025-11-08T13:25:29.911449Z",
     "shell.execute_reply.started": "2025-11-08T13:25:28.997409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Donc, je suis sur un site Web pour essayer de trouver un emploi et j'ai dû répondre à certaines questions et j'ai dû dire ce que j'étudiais et j'ai eu quelques difficultés à trouver le bon sujet. et avez-vous trouvé?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" So, I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic. and did you find it? yeah\"\n",
    "translate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c9eaa5-40d1-492b-8ec4-6c4436c2cada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:31.302364Z",
     "iopub.status.busy": "2025-11-08T13:25:31.302203Z",
     "iopub.status.idle": "2025-11-08T13:25:33.468098Z",
     "shell.execute_reply": "2025-11-08T13:25:33.467729Z",
     "shell.execute_reply.started": "2025-11-08T13:25:31.302355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 ms ± 16.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit translate_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fcea3-1c70-40c9-9cd6-6bc88b940153",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaac3ad-6919-44d5-a0a2-89510a9a8485",
   "metadata": {},
   "source": [
    "opus-mt-en-fr on RTX 4090 -> 258 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee27a8d-e3f0-4694-9b22-d44bf31dbb84",
   "metadata": {},
   "source": [
    "## Gradio speech transcription and translation UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea6f7f-4f58-4b1f-9245-5594f5c1001d",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93acb2ef-2b38-4149-85ab-eac5f566c8af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:38.017714Z",
     "iopub.status.busy": "2025-11-08T13:25:38.017540Z",
     "iopub.status.idle": "2025-11-08T13:25:38.166586Z",
     "shell.execute_reply": "2025-11-08T13:25:38.165880Z",
     "shell.execute_reply.started": "2025-11-08T13:25:38.017704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/home/jupyterlab/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m275 packages\u001b[0m \u001b[2min 0.69ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m178 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad4380ce-3f9a-4bd7-be08-f04eae90edcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:38.249059Z",
     "iopub.status.busy": "2025-11-08T13:25:38.248863Z",
     "iopub.status.idle": "2025-11-08T13:25:38.253551Z",
     "shell.execute_reply": "2025-11-08T13:25:38.253168Z",
     "shell.execute_reply.started": "2025-11-08T13:25:38.249047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.49.1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('gradio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6af53-d400-45af-b45b-22184ec6cfb5",
   "metadata": {},
   "source": [
    "### Define audio processing function and build the associated UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb05c335-ea89-4a7a-9407-d7ab2da5f369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:41.391272Z",
     "iopub.status.busy": "2025-11-08T13:25:41.391093Z",
     "iopub.status.idle": "2025-11-08T13:25:41.394230Z",
     "shell.execute_reply": "2025-11-08T13:25:41.393805Z",
     "shell.execute_reply.started": "2025-11-08T13:25:41.391264Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Single user application => simplify the implementation with a global audio buffer\n",
    "audiobuffer = RollingAudioBuffer()\n",
    "\n",
    "# Input: tuple (sampling_rate,input_samples) received from gr.Audio component, audio_samples format is 48 kHz mono 16 bits integers\n",
    "# The input_samples are converted and added to the global audio buffer, which is then transcribed to text and translated \n",
    "# Output: tuple (english_text, french_text) transcribed and translated from the global audio buffer\n",
    "def process_audio(gradio_audio):\n",
    "    start_time = time.time()\n",
    "    sampling_date, input_samples = gradio_audio\n",
    "    audiobuffer.append_input_samples(input_samples)\n",
    "    english_text = transcribe_speech_to_text_hf(audiobuffer)\n",
    "    if len(english_text)>3:\n",
    "        french_text = translate_text(english_text)\n",
    "    else:\n",
    "        french_text = \"\"\n",
    "    end_time = time.time()\n",
    "    refresh_rate = f\"{end_time-start_time:.2f} sec\"\n",
    "    return english_text, french_text, refresh_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d850b969-eb71-48b3-b4f7-195abf2feb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:42.021273Z",
     "iopub.status.busy": "2025-11-08T13:25:42.020899Z",
     "iopub.status.idle": "2025-11-08T13:25:42.993659Z",
     "shell.execute_reply": "2025-11-08T13:25:42.992937Z",
     "shell.execute_reply.started": "2025-11-08T13:25:42.021250Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def on_clear():\n",
    "    audiobuffer.clear()\n",
    "    return (\"\", \"\", \"\")\n",
    "\n",
    "# Define custom CSS\n",
    "custom_css = \"\"\"\n",
    "    #english_transcription textarea, #french_translation textarea {\n",
    "        font-size: 20px !important;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio Blocks interface\n",
    "with gr.Blocks(css=custom_css) as interface:\n",
    "    gr.Markdown(\"# Real time speech translation\")\n",
    "    gr.Markdown(\"This application transcribes your english speech in real-time and translates it to French.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(sources=[\"microphone\"], streaming=True, scale=5)\n",
    "        clear_button = gr.Button(\"Clear\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        english_output = gr.Textbox(label=\"Transcription (English)\", lines=10, elem_id=\"english_transcription\")\n",
    "        french_output = gr.Textbox(label=\"Translation (French)\", lines=10, elem_id=\"french_translation\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        refresh_rate = gr.Textbox(label=\"Refresh rate\")\n",
    "    \n",
    "    clear_button.click(fn=on_clear, inputs=None, outputs=[english_output, french_output, refresh_rate])\n",
    "    \n",
    "    audio_input.stream(process_audio, inputs=audio_input, outputs=[english_output, french_output, refresh_rate]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4bbca-cf57-4ba1-9450-196fa517d5d1",
   "metadata": {},
   "source": [
    "### Display and stop the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85a44859-1e1c-44fa-84fe-6a6b92520334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:43.310567Z",
     "iopub.status.busy": "2025-11-08T13:25:43.310395Z",
     "iopub.status.idle": "2025-11-08T13:25:43.312698Z",
     "shell.execute_reply": "2025-11-08T13:25:43.312362Z",
     "shell.execute_reply.started": "2025-11-08T13:25:43.310557Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58cef94a-bf37-4a66-90c7-fec13ea7cf95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:43.685069Z",
     "iopub.status.busy": "2025-11-08T13:25:43.684786Z",
     "iopub.status.idle": "2025-11-08T13:25:43.688242Z",
     "shell.execute_reply": "2025-11-08T13:25:43.687610Z",
     "shell.execute_reply.started": "2025-11-08T13:25:43.685054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Port exposed by wordslab notebooks\n",
    "port = int(os.getenv(\"USER_APP1_PORT\"))\n",
    "url = os.getenv(\"USER_APP1_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46ae224-7340-4ed9-8d4a-980a7f5eb9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:44.669126Z",
     "iopub.status.busy": "2025-11-08T13:25:44.668965Z",
     "iopub.status.idle": "2025-11-08T13:25:44.672274Z",
     "shell.execute_reply": "2025-11-08T13:25:44.671811Z",
     "shell.execute_reply.started": "2025-11-08T13:25:44.669115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional https certificate\n",
    "workspace = os.getenv(\"WORDSLAB_WORKSPACE\")\n",
    "keyfile = os.path.join(workspace, \".secrets\", \"certificate-key.pem\")\n",
    "certfile = os.path.join(workspace, \".secrets\", \"certificate.pem\")\n",
    "\n",
    "# Only add SSL keys if they exist\n",
    "launch_kwargs = { }\n",
    "if os.path.isfile(keyfile) and os.path.isfile(certfile):\n",
    "    launch_kwargs[\"ssl_keyfile\"] = keyfile\n",
    "    launch_kwargs[\"ssl_certfile\"] = certfile\n",
    "    launch_kwargs[\"ssl_verify\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec56a62-9b77-4cf7-a075-bac4387ced25",
   "metadata": {},
   "source": [
    "Start the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8161760-b628-48c3-bb9e-1c8e90a94fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:46.093978Z",
     "iopub.status.busy": "2025-11-08T13:25:46.093799Z",
     "iopub.status.idle": "2025-11-08T13:25:46.178302Z",
     "shell.execute_reply": "2025-11-08T13:25:46.177899Z",
     "shell.execute_reply.started": "2025-11-08T13:25:46.093967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  https://0.0.0.0:8883\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://localhost:8883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(server_name=\"0.0.0.0\", server_port=port, **launch_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871021a5-0d6a-443f-80e5-1b91e3c2ec7e",
   "metadata": {},
   "source": [
    "Navigate to this URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a76589-e2d2-4013-adc2-ffb7ff96162c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:25:48.370011Z",
     "iopub.status.busy": "2025-11-08T13:25:48.369223Z",
     "iopub.status.idle": "2025-11-08T13:25:48.373854Z",
     "shell.execute_reply": "2025-11-08T13:25:48.373474Z",
     "shell.execute_reply.started": "2025-11-08T13:25:48.369979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://192.168.1.197:8883'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1228dd2-58c8-462e-9429-49439edaf88e",
   "metadata": {},
   "source": [
    "And then when you are done, stop the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34740e6d-dbf2-47ed-8108-9e33ce750739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:28:18.360724Z",
     "iopub.status.busy": "2025-11-08T13:28:18.360023Z",
     "iopub.status.idle": "2025-11-08T13:28:18.558229Z",
     "shell.execute_reply": "2025-11-08T13:28:18.557848Z",
     "shell.execute_reply.started": "2025-11-08T13:28:18.360706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8883\n"
     ]
    }
   ],
   "source": [
    "interface.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
