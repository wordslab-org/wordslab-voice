{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd66fbdb-5fed-4b9f-9f76-8351102f616d",
   "metadata": {},
   "source": [
    "# Real-time speech transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968adba8-b4dc-4541-b5ba-339a8e8af1bd",
   "metadata": {},
   "source": [
    "## Audio buffer management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0269d88-e7f0-4d57-820d-af5403281b65",
   "metadata": {},
   "source": [
    "The audio samples for real-time speech transcription will be accumulated in a rolling audio buffer with a limited duration (< 30 sec for whsiper).\n",
    "\n",
    "You don't need to understand the code below, you can just execute the cell to use the class in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05032d8f-2cfe-4538-9196-fc498c837bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:25.054417Z",
     "iopub.status.busy": "2025-11-07T23:25:25.054315Z",
     "iopub.status.idle": "2025-11-07T23:25:25.096982Z",
     "shell.execute_reply": "2025-11-07T23:25:25.096736Z",
     "shell.execute_reply.started": "2025-11-07T23:25:25.054409Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 1. Aggregates audio samples in a buffer and keeps only the last max_length_sec seconds.\n",
    "# 2. Converts the audio format from input to output sampling rate and dtype.\n",
    "class RollingAudioBuffer:\n",
    "\n",
    "    # Default max length (whisper): 30 sec\n",
    "    # Default input audio format (gradio): 48 kHz 16 bits int\n",
    "    # Default output audio format (whisper): 16 kHz 32 bits float\n",
    "    def __init__(self, max_length_sec=30, input_sampling_rate=48000, input_dtype=np.int16, output_sampling_rate=16000, output_dtype=np.float32):\n",
    "        \n",
    "        self.input_sampling_rate = input_sampling_rate\n",
    "        self.input_dtype = input_dtype\n",
    "        self.output_sampling_rate = output_sampling_rate\n",
    "        self.output_dtype = output_dtype\n",
    "\n",
    "        self.output_buffer = np.empty((0,), dtype=output_dtype)\n",
    "        self.max_buffer_length = max_length_sec * output_sampling_rate\n",
    "\n",
    "    # input_samples should be a numpy array recorded with input_sampling_rate and input_dtype\n",
    "    def append_input_samples(self, input_samples):\n",
    "\n",
    "        # Convert input sampling rate to output sampling rate\n",
    "        if self.input_sampling_rate==48000 and self.output_sampling_rate==16000:\n",
    "            input_samples = input_samples[::3]\n",
    "        elif self.input_sampling_rate!=self.output_sampling_rate:\n",
    "            raise TypeError(f\"Conversion of input sampling rate {self.input_sampling_rate} to output sampling rate {self.output_sampling_rate} is not supported\")\n",
    "        \n",
    "        # Convert input dtype to output dtype\n",
    "        if self.input_dtype==np.int16 and self.output_dtype==np.float32:\n",
    "            input_samples = input_samples.astype(np.float32)\n",
    "            max_value = np.max(np.abs(input_samples))\n",
    "            if max_value==0:\n",
    "                return\n",
    "            else:\n",
    "                input_samples /= max_value\n",
    "        elif self.input_dtype!=self.output_dtype:\n",
    "            raise TypeError(f\"Conversion of input type {self.input_type} to output type {self.output_type} is not supported\")\n",
    "\n",
    "        # Accumulate samples in the output buffer with a rolling window\n",
    "        self.output_buffer = np.concatenate((self.output_buffer, input_samples))\n",
    "        if len(self.output_buffer) > self.max_buffer_length:\n",
    "            self.output_buffer = self.output_buffer[len(self.output_buffer)-self.max_buffer_length:]\n",
    "    \n",
    "    # output buffer is a numpy array ready to be used by the transcription model\n",
    "    def get_output_samples(self):\n",
    "        return self.output_buffer\n",
    "\n",
    "    def clear(self):\n",
    "        self.output_buffer = np.empty((0,), dtype=self.output_dtype)\n",
    "\n",
    "    # Loads the output buffer from a file\n",
    "    def load(self, filename):\n",
    "        self.output_buffer = np.load(filename)\n",
    "\n",
    "    # Saves the output buffer from a file\n",
    "    def save(self, filename):\n",
    "        np.save(filename, self.output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962d4b5-e561-4eaa-ada6-3337b3721e3d",
   "metadata": {},
   "source": [
    "Load test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d64ace-a949-40e5-a88e-199077fe23f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:25.098134Z",
     "iopub.status.busy": "2025-11-07T23:25:25.097801Z",
     "iopub.status.idle": "2025-11-07T23:25:25.101182Z",
     "shell.execute_reply": "2025-11-07T23:25:25.100764Z",
     "shell.execute_reply.started": "2025-11-07T23:25:25.098120Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobuffer = RollingAudioBuffer()\n",
    "audiobuffer.load(\"data/test_audio_en.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ee8be-4642-4ed2-8e18-a9529ea6e300",
   "metadata": {},
   "source": [
    "## Huggingface automatic-speech-recognition pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5d533-b622-4b7c-9a02-7588e999d8fb",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb745167-5f0e-4ca1-86cc-861def45e453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:26.663324Z",
     "iopub.status.busy": "2025-11-07T23:25:26.663152Z",
     "iopub.status.idle": "2025-11-07T23:25:26.800643Z",
     "shell.execute_reply": "2025-11-07T23:25:26.800101Z",
     "shell.execute_reply.started": "2025-11-07T23:25:26.663315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "libavutil      58. 29.100 / 58. 29.100\n",
      "libavcodec     60. 31.102 / 60. 31.102\n",
      "libavformat    60. 16.100 / 60. 16.100\n",
      "libavdevice    60.  3.100 / 60.  3.100\n",
      "libavfilter     9. 12.100 /  9. 12.100\n",
      "libswscale      7.  5.100 /  7.  5.100\n",
      "libswresample   4. 12.100 /  4. 12.100\n",
      "libpostproc    57.  3.100 / 57.  3.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37208fa3-fe1e-4255-820c-26b3a9ef5d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:26.887571Z",
     "iopub.status.busy": "2025-11-07T23:25:26.887409Z",
     "iopub.status.idle": "2025-11-07T23:25:27.012410Z",
     "shell.execute_reply": "2025-11-07T23:25:27.011731Z",
     "shell.execute_reply.started": "2025-11-07T23:25:26.887559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/home/jupyterlab/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m263 packages\u001b[0m \u001b[2min 0.56ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m159 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dacd0d5-4f97-40f2-948c-b0f2e7545fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:27.425663Z",
     "iopub.status.busy": "2025-11-07T23:25:27.425481Z",
     "iopub.status.idle": "2025-11-07T23:25:27.427886Z",
     "shell.execute_reply": "2025-11-07T23:25:27.427407Z",
     "shell.execute_reply.started": "2025-11-07T23:25:27.425652Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae56fa1-92c1-49eb-b571-539616487108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:27.690230Z",
     "iopub.status.busy": "2025-11-07T23:25:27.689805Z",
     "iopub.status.idle": "2025-11-07T23:25:27.699733Z",
     "shell.execute_reply": "2025-11-07T23:25:27.699334Z",
     "shell.execute_reply.started": "2025-11-07T23:25:27.690201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.57.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15aa5d0e-9fa4-4626-a9b8-0a54f519f4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:28.089167Z",
     "iopub.status.busy": "2025-11-07T23:25:28.089011Z",
     "iopub.status.idle": "2025-11-07T23:25:28.093321Z",
     "shell.execute_reply": "2025-11-07T23:25:28.092862Z",
     "shell.execute_reply.started": "2025-11-07T23:25:28.089158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('accelerate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ce54d-74d3-48db-894d-2a02a082fd9c",
   "metadata": {},
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1cbc6d-3101-45f2-a3f4-0b75f47f4a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:30.940920Z",
     "iopub.status.busy": "2025-11-07T23:25:30.940597Z",
     "iopub.status.idle": "2025-11-07T23:25:35.489196Z",
     "shell.execute_reply": "2025-11-07T23:25:35.488522Z",
     "shell.execute_reply.started": "2025-11-07T23:25:30.940902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/wordslab-voice/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Load whisper-small in 16 bits with flash attention 2 on the GPU\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\", \n",
    "                       model_kwargs={\"dtype\":torch.float16, \"attn_implementation\":\"sdpa\", \"device_map\":0}, \n",
    "                       generate_kwargs = {\"task\":\"transcribe\", \"language\":\"english\"})\n",
    "\n",
    "# torch compile the model to speed up inference\n",
    "transcriber.model.model = torch.compile(transcriber.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be0b32a-df35-4fbe-8754-69420cd4c94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:35.489851Z",
     "iopub.status.busy": "2025-11-07T23:25:35.489626Z",
     "iopub.status.idle": "2025-11-07T23:25:35.492067Z",
     "shell.execute_reply": "2025-11-07T23:25:35.491634Z",
     "shell.execute_reply.started": "2025-11-07T23:25:35.489841Z"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_speech_to_text_hf(audiobuffer):\n",
    "    return transcriber({\"sampling_rate\": audiobuffer.output_sampling_rate, \"raw\": audiobuffer.output_buffer})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d0bfbc-7fc4-4eb5-b44e-31cf50d75518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:35.492368Z",
     "iopub.status.busy": "2025-11-07T23:25:35.492280Z",
     "iopub.status.idle": "2025-11-07T23:25:42.988659Z",
     "shell.execute_reply": "2025-11-07T23:25:42.988173Z",
     "shell.execute_reply.started": "2025-11-07T23:25:35.492361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" So I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic and the... voilà! You didn't find it? Yeah!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_speech_to_text_hf(audiobuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5773f50-3d76-4bb2-8698-6e2ea392f414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:25:42.989356Z",
     "iopub.status.busy": "2025-11-07T23:25:42.989255Z",
     "iopub.status.idle": "2025-11-07T23:25:46.497529Z",
     "shell.execute_reply": "2025-11-07T23:25:46.497099Z",
     "shell.execute_reply.started": "2025-11-07T23:25:42.989347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427 ms ± 34.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit transcribe_speech_to_text_hf(audiobuffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9f9bc-3612-4505-92e5-bee06c2ce2a8",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d42864-f44e-4048-a86d-af2d34baa7df",
   "metadata": {},
   "source": [
    "whisper-small on RTX 4090 -> 429 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ac740-dda6-46ad-aa48-8646b3bb6e93",
   "metadata": {},
   "source": [
    "## Translation with Helsinki-NLP/opus-mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd131d-2ffb-46cb-a3d2-8966c6f9087a",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ecd8f64-8bfe-47a2-90ce-122cac596eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:26:34.932687Z",
     "iopub.status.busy": "2025-11-07T23:26:34.932502Z",
     "iopub.status.idle": "2025-11-07T23:26:36.337889Z",
     "shell.execute_reply": "2025-11-07T23:26:36.336599Z",
     "shell.execute_reply.started": "2025-11-07T23:26:34.932672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/home/jupyterlab/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m264 packages\u001b[0m \u001b[2min 1.04s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 155ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msacremoses\u001b[0m\u001b[2m==0.1.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8613669-d990-4245-993b-0f1193b7d08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:26:39.160776Z",
     "iopub.status.busy": "2025-11-07T23:26:39.160575Z",
     "iopub.status.idle": "2025-11-07T23:26:39.165435Z",
     "shell.execute_reply": "2025-11-07T23:26:39.165061Z",
     "shell.execute_reply.started": "2025-11-07T23:26:39.160767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sentencepiece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61ad5a5-8fa8-4035-a0c3-22482e1d6d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:26:41.916000Z",
     "iopub.status.busy": "2025-11-07T23:26:41.915795Z",
     "iopub.status.idle": "2025-11-07T23:26:41.919713Z",
     "shell.execute_reply": "2025-11-07T23:26:41.919276Z",
     "shell.execute_reply.started": "2025-11-07T23:26:41.915991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('sacremoses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061aaf1-8b7c-4d74-905c-5f672adfe0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T14:08:42.010912Z",
     "iopub.status.busy": "2024-07-06T14:08:42.010537Z",
     "iopub.status.idle": "2024-07-06T14:08:42.016888Z",
     "shell.execute_reply": "2024-07-06T14:08:42.015642Z",
     "shell.execute_reply.started": "2024-07-06T14:08:42.010887Z"
    }
   },
   "source": [
    "### Load model and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525f99ea-d9bf-4e75-964e-1314cb55716d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:31:19.440881Z",
     "iopub.status.busy": "2025-11-07T23:31:19.440680Z",
     "iopub.status.idle": "2025-11-07T23:31:20.960152Z",
     "shell.execute_reply": "2025-11-07T23:31:20.959655Z",
     "shell.execute_reply.started": "2025-11-07T23:31:19.440870Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "opusmtmodel = MarianMTModel.from_pretrained(model_name, attn_implementation=\"sdpa\", device_map=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91ca64d0-2d06-466a-a10b-68d76a91846f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:31:20.960752Z",
     "iopub.status.busy": "2025-11-07T23:31:20.960647Z",
     "iopub.status.idle": "2025-11-07T23:31:20.962912Z",
     "shell.execute_reply": "2025-11-07T23:31:20.962562Z",
     "shell.execute_reply.started": "2025-11-07T23:31:20.960744Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "    translated = opusmtmodel.generate(**encoded)\n",
    "    decoded = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88a1087c-d086-4315-b41a-27c284dc11d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:31:20.963322Z",
     "iopub.status.busy": "2025-11-07T23:31:20.963206Z",
     "iopub.status.idle": "2025-11-07T23:31:21.361529Z",
     "shell.execute_reply": "2025-11-07T23:31:21.361178Z",
     "shell.execute_reply.started": "2025-11-07T23:31:20.963315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Donc, je suis sur un site Web pour essayer de trouver un emploi et j'ai dû répondre à certaines questions et j'ai dû dire ce que j'étudiais et j'ai eu quelques difficultés à trouver le bon sujet. et avez-vous trouvé?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" So, I am on a website to try and find a job and I had to answer to some questions and I had to say what I was studying and I had some difficulties to find the good topic. and did you find it? yeah\"\n",
    "translate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3c9eaa5-40d1-492b-8ec4-6c4436c2cada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:31:21.362113Z",
     "iopub.status.busy": "2025-11-07T23:31:21.362013Z",
     "iopub.status.idle": "2025-11-07T23:31:23.354378Z",
     "shell.execute_reply": "2025-11-07T23:31:23.354018Z",
     "shell.execute_reply.started": "2025-11-07T23:31:21.362105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 ms ± 12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit translate_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fcea3-1c70-40c9-9cd6-6bc88b940153",
   "metadata": {},
   "source": [
    "### Performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaac3ad-6919-44d5-a0a2-89510a9a8485",
   "metadata": {},
   "source": [
    "opus-mt-en-fr on RTX 4090 -> 249 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee27a8d-e3f0-4694-9b22-d44bf31dbb84",
   "metadata": {},
   "source": [
    "## Gradio speech transcription and translation UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea6f7f-4f58-4b1f-9245-5594f5c1001d",
   "metadata": {},
   "source": [
    "### Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93acb2ef-2b38-4149-85ab-eac5f566c8af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:32:31.848380Z",
     "iopub.status.busy": "2025-11-07T23:32:31.847911Z",
     "iopub.status.idle": "2025-11-07T23:32:32.084917Z",
     "shell.execute_reply": "2025-11-07T23:32:32.084232Z",
     "shell.execute_reply.started": "2025-11-07T23:32:31.848343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`VIRTUAL_ENV=/home/jupyterlab/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m275 packages\u001b[0m \u001b[2min 0.71ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m178 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad4380ce-3f9a-4bd7-be08-f04eae90edcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:32:33.031700Z",
     "iopub.status.busy": "2025-11-07T23:32:33.031252Z",
     "iopub.status.idle": "2025-11-07T23:32:33.041725Z",
     "shell.execute_reply": "2025-11-07T23:32:33.040900Z",
     "shell.execute_reply.started": "2025-11-07T23:32:33.031668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.49.1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.metadata.version('gradio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6af53-d400-45af-b45b-22184ec6cfb5",
   "metadata": {},
   "source": [
    "### Define audio processing function and build the associated UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb05c335-ea89-4a7a-9407-d7ab2da5f369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:33:03.304683Z",
     "iopub.status.busy": "2025-11-07T23:33:03.304506Z",
     "iopub.status.idle": "2025-11-07T23:33:03.308794Z",
     "shell.execute_reply": "2025-11-07T23:33:03.307643Z",
     "shell.execute_reply.started": "2025-11-07T23:33:03.304675Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Single user application => simplify the implementation with a global audio buffer\n",
    "audiobuffer = RollingAudioBuffer()\n",
    "\n",
    "# Input: tuple (sampling_rate,input_samples) received from gr.Audio component, audio_samples format is 48 kHz mono 16 bits integers\n",
    "# The input_samples are converted and added to the global audio buffer, which is then transcribed to text and translated \n",
    "# Output: tuple (english_text, french_text) transcribed and translated from the global audio buffer\n",
    "def process_audio(gradio_audio):\n",
    "    start_time = time.time()\n",
    "    sampling_date, input_samples = gradio_audio\n",
    "    audiobuffer.append_input_samples(input_samples)\n",
    "    english_text = transcribe_speech_to_text_fw(audiobuffer)\n",
    "    if len(english_text)>3:\n",
    "        french_text = translate_text(english_text)\n",
    "    else:\n",
    "        french_text = \"\"\n",
    "    end_time = time.time()\n",
    "    refresh_rate = f\"{end_time-start_time:.2f} sec\"\n",
    "    return english_text, french_text, refresh_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d850b969-eb71-48b3-b4f7-195abf2feb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:33:55.617972Z",
     "iopub.status.busy": "2025-11-07T23:33:55.617806Z",
     "iopub.status.idle": "2025-11-07T23:33:57.560801Z",
     "shell.execute_reply": "2025-11-07T23:33:57.560272Z",
     "shell.execute_reply.started": "2025-11-07T23:33:55.617963Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def on_clear():\n",
    "    audiobuffer.clear()\n",
    "    return (\"\", \"\", \"\")\n",
    "\n",
    "# Define custom CSS\n",
    "custom_css = \"\"\"\n",
    "    #english_transcription textarea, #french_translation textarea {\n",
    "        font-size: 20px !important;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio Blocks interface\n",
    "with gr.Blocks(css=custom_css) as interface:\n",
    "    gr.Markdown(\"# Real time speech translation\")\n",
    "    gr.Markdown(\"This application transcribes your english speech in real-time and translates it to French.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(sources=[\"microphone\"], streaming=True, scale=5)\n",
    "        clear_button = gr.Button(\"Clear\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        english_output = gr.Textbox(label=\"Transcription (English)\", lines=10, elem_id=\"english_transcription\")\n",
    "        french_output = gr.Textbox(label=\"Translation (French)\", lines=10, elem_id=\"french_translation\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        refresh_rate = gr.Textbox(label=\"Refresh rate\")\n",
    "    \n",
    "    clear_button.click(fn=on_clear, inputs=None, outputs=[english_output, french_output, refresh_rate])\n",
    "    \n",
    "    audio_input.stream(process_audio, inputs=audio_input, outputs=[english_output, french_output, refresh_rate]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4bbca-cf57-4ba1-9450-196fa517d5d1",
   "metadata": {},
   "source": [
    "### Display and stop the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85a44859-1e1c-44fa-84fe-6a6b92520334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:38:13.486069Z",
     "iopub.status.busy": "2025-11-07T23:38:13.485857Z",
     "iopub.status.idle": "2025-11-07T23:38:13.488505Z",
     "shell.execute_reply": "2025-11-07T23:38:13.488120Z",
     "shell.execute_reply.started": "2025-11-07T23:38:13.486054Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58cef94a-bf37-4a66-90c7-fec13ea7cf95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:56:50.651415Z",
     "iopub.status.busy": "2025-11-07T23:56:50.651045Z",
     "iopub.status.idle": "2025-11-07T23:56:50.655901Z",
     "shell.execute_reply": "2025-11-07T23:56:50.655068Z",
     "shell.execute_reply.started": "2025-11-07T23:56:50.651392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Port exposed by wordslab notebooks\n",
    "port = int(os.getenv(\"USER_APP1_PORT\"))\n",
    "url = os.getenv(\"USER_APP1_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d46ae224-7340-4ed9-8d4a-980a7f5eb9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:04:02.984204Z",
     "iopub.status.busy": "2025-11-08T00:04:02.983992Z",
     "iopub.status.idle": "2025-11-08T00:04:02.987554Z",
     "shell.execute_reply": "2025-11-08T00:04:02.987007Z",
     "shell.execute_reply.started": "2025-11-08T00:04:02.984191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional https certificate\n",
    "workspace = os.getenv(\"WORDSLAB_WORKSPACE\")\n",
    "keyfile = os.path.join(workspace, \".secrets\", \"certificate-key.pem\")\n",
    "certfile = os.path.join(workspace, \".secrets\", \"certificate.pem\")\n",
    "\n",
    "# Only add SSL keys if they exist\n",
    "launch_kwargs = { }\n",
    "if os.path.isfile(keyfile) and os.path.isfile(certfile):\n",
    "    launch_kwargs[\"ssl_keyfile\"] = keyfile\n",
    "    launch_kwargs[\"ssl_certfile\"] = certfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8161760-b628-48c3-bb9e-1c8e90a94fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:04:21.157844Z",
     "iopub.status.busy": "2025-11-08T00:04:21.157438Z",
     "iopub.status.idle": "2025-11-08T00:04:21.209106Z",
     "shell.execute_reply": "2025-11-08T00:04:21.208628Z",
     "shell.execute_reply.started": "2025-11-08T00:04:21.157809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:8883\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:8883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(server_name=\"0.0.0.0\", server_port=port) #, **launch_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871021a5-0d6a-443f-80e5-1b91e3c2ec7e",
   "metadata": {},
   "source": [
    "Navigate to this URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15a76589-e2d2-4013-adc2-ffb7ff96162c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T23:48:13.259821Z",
     "iopub.status.busy": "2025-11-07T23:48:13.259624Z",
     "iopub.status.idle": "2025-11-07T23:48:13.263079Z",
     "shell.execute_reply": "2025-11-07T23:48:13.262736Z",
     "shell.execute_reply.started": "2025-11-07T23:48:13.259806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://192.168.1.197:8883'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34740e6d-dbf2-47ed-8108-9e33ce750739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T00:04:15.509432Z",
     "iopub.status.busy": "2025-11-08T00:04:15.509271Z",
     "iopub.status.idle": "2025-11-08T00:04:15.666463Z",
     "shell.execute_reply": "2025-11-08T00:04:15.666030Z",
     "shell.execute_reply.started": "2025-11-08T00:04:15.509423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8883\n"
     ]
    }
   ],
   "source": [
    "interface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef14c3-ae34-4743-b210-26cf6a658f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
