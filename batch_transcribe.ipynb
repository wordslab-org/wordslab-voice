{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e014d6c1-2727-4e4a-83ff-203f8e7b3f2a",
   "metadata": {},
   "source": [
    "# Transcribe audio files in batch mode as fast as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d1fda0-bbd8-4b3e-bd9c-57164c860bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:25:09.596992Z",
     "iopub.status.busy": "2024-09-29T07:25:09.596545Z",
     "iopub.status.idle": "2024-09-29T07:25:09.602935Z",
     "shell.execute_reply": "2024-09-29T07:25:09.601931Z",
     "shell.execute_reply.started": "2024-09-29T07:25:09.596961Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56df76d7-4856-45fc-9f91-e361b1bb4d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:07:17.512126Z",
     "iopub.status.busy": "2024-09-29T07:07:17.511762Z",
     "iopub.status.idle": "2024-09-29T07:07:17.522523Z",
     "shell.execute_reply": "2024-09-29T07:07:17.522269Z",
     "shell.execute_reply.started": "2024-09-29T07:07:17.512102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158edb7-33a0-4628-9eaf-9db3cce2e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9039795-f1f1-49d1-a0b6-cf92cf22c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11130d56-5a5b-40e8-b85c-d90dfd9577f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:25:11.304413Z",
     "iopub.status.busy": "2024-09-29T07:25:11.303756Z",
     "iopub.status.idle": "2024-09-29T07:25:11.314357Z",
     "shell.execute_reply": "2024-09-29T07:25:11.313938Z",
     "shell.execute_reply.started": "2024-09-29T07:25:11.304385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.45.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba96ccf-f1b0-4097-aa8f-209eae467360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:25:11.685464Z",
     "iopub.status.busy": "2024-09-29T07:25:11.685140Z",
     "iopub.status.idle": "2024-09-29T07:25:11.691436Z",
     "shell.execute_reply": "2024-09-29T07:25:11.691172Z",
     "shell.execute_reply.started": "2024-09-29T07:25:11.685441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.34.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('accelerate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196fc82-43f8-490a-a9e9-e8fb90427038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73db5e4-7516-484a-a76e-05aed1ed1b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:30:55.669480Z",
     "iopub.status.busy": "2024-09-29T07:30:55.669060Z",
     "iopub.status.idle": "2024-09-29T07:30:55.679344Z",
     "shell.execute_reply": "2024-09-29T07:30:55.678910Z",
     "shell.execute_reply.started": "2024-09-29T07:30:55.669448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('flash_attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44703518-d75c-4223-93b7-92457811f4b0",
   "metadata": {},
   "source": [
    "## Huggingface Whisper\n",
    "\n",
    "https://github.com/huggingface/speech-to-speech/blob/main/STT/whisper_stt_handler.py\n",
    "\n",
    "https://huggingface.co/eustlb/distil-large-v3-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcb2fd4-e273-4125-8269-7874e7516d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:20:09.705627Z",
     "iopub.status.busy": "2024-09-29T14:20:09.705304Z",
     "iopub.status.idle": "2024-09-29T14:20:13.334587Z",
     "shell.execute_reply": "2024-09-29T14:20:13.334213Z",
     "shell.execute_reply.started": "2024-09-29T14:20:09.705605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"eustlb/distil-large-v3-fr\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, \n",
    "    use_safetensors=True, low_cpu_mem_usage=True, device_map=device, \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype\n",
    ")\n",
    "\n",
    "# warmup\n",
    "dummy_input = torch.randn( (1, model.config.num_mel_bins, 3000), dtype=torch_dtype, device=device)\n",
    "_ = model.generate(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1865cd0b-eb16-4c1c-8064-4a6edac0cf23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:20:58.286337Z",
     "iopub.status.busy": "2024-09-29T14:20:58.285968Z",
     "iopub.status.idle": "2024-09-29T14:21:25.068208Z",
     "shell.execute_reply": "2024-09-29T14:21:25.067815Z",
     "shell.execute_reply.started": "2024-09-29T14:20:58.286310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ok, donc dans la première partie, on a fait beaucoup de choses, on s'est posé beaucoup de questions pour pouvoir cadrer, sélectionner, identifier des projets à Basse-Dia qui soient pertinents. La pha\n"
     ]
    }
   ],
   "source": [
    "# ./audio/2024-09-19 16-32-50.mp3\n",
    "# - batch size 64, flash attention 2, no compile: 6.14 sec\n",
    "# - batch size 64, sdpa attention, compile default with fullgraph: 18 sec (first test) / 34 sec (second test)\n",
    "# => follow line by line the example of https://huggingface.co/eustlb/distil-large-v3-fr, it is the fastest combination\n",
    "\n",
    "# Test with 2 mp3 files\n",
    "# - small: 24 min 47 sec (1487 sec), 22.7 MB file\n",
    "# - big : 1h 24 min 19 sec (5059 sec), 77.2 MB file\n",
    "\n",
    "# Sequential long-form: pipe(mp3file)\n",
    "# - gpu memory = 3.1 GB -> 27 sec / 94 sec\n",
    "\n",
    "# Chunked long-form: pipe(mp3file, chunk_length_s=25, batch_size=xxx)\n",
    "# batch size 1 : gpu memory = 3.1 GB -> 33 sec / 111 sec\n",
    "# batch size 8 : gpu memory = 3.6 GB -> 13 sec / 46 sec\n",
    "# batch size 16 : gpu memory = 4.4 GB -> 11 sec / 37 sec\n",
    "# batch size 32 : gpu memory = 5.1 GB -> 9.5 sec / 34 sec\n",
    "# batch size 64 : gpu memory = 7.2 GB -> 10.3 sec / 31 sec\n",
    "# batch size 128 : gpu memory = 11 GB -> 9.3 sec / 33 sec\n",
    "# Chunked attention: pipe(mp3file, chunk_length_s=25, batch_size=xxx)\n",
    "\n",
    "# Sequential long-form algorithm + batch_size 2: pipe([mp3file1, mp3file2], batch_size=2)\n",
    "# => RuntimeError: The expanded size of the tensor (505922) must match the existing size (148730) at non-singleton dimension 1.  Target sizes: [128, 505922].  Tensor sizes: [128, 148730]\n",
    "\n",
    "result = pipe(\"./audio/2024-09-19 16-32-50.mp3\")\n",
    "print(result[\"text\"][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67d5b25-eb54-4118-822c-60447350dfa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:23:39.968711Z",
     "iopub.status.busy": "2024-09-29T14:23:39.968329Z",
     "iopub.status.idle": "2024-09-29T14:25:10.907269Z",
     "shell.execute_reply": "2024-09-29T14:25:10.906719Z",
     "shell.execute_reply.started": "2024-09-29T14:23:39.968686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ok. Donc, on poursuit notre énumération de tous les aspects à prendre en compte pour voir si un projet doit être fait, faisable et rentable, et raisonnable en matière d'environnement, etc. Donc, poin\n"
     ]
    }
   ],
   "source": [
    "result = pipe(\"./audio/2024-09-19 15-03-35.mp3\")\n",
    "print(result[\"text\"][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d94411-e680-405a-9343-f5069b39ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe([\"./audio/2024-09-19 15-03-35.mp3\",\"./audio/2024-09-19 16-32-50.mp3\"], batch_size=2)\n",
    "for result in results: print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5206c4ef-00f8-4950-a039-61073d111d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:42:59.105830Z",
     "iopub.status.busy": "2024-09-29T14:42:59.105423Z",
     "iopub.status.idle": "2024-09-29T14:54:02.698117Z",
     "shell.execute_reply": "2024-09-29T14:54:02.697721Z",
     "shell.execute_reply.started": "2024-09-29T14:42:59.105802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 2024-09-24 12-27-09.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-24 12-27-09.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 12-27-09_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 12-27-09_chunked.txt\n",
      "- 2024-09-24 10-46-15.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-24 10-46-15.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 10-46-15_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 10-46-15_chunked.txt\n",
      "- 2024-09-24 11-39-13.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-24 11-39-13.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 11-39-13_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 11-39-13_chunked.txt\n",
      "- 2024-09-26 15-35-04.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-26 15-35-04.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-26 15-35-04_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-26 15-35-04_chunked.txt\n",
      "- 2024-09-19 13-34-26.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-19 13-34-26.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 13-34-26_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 13-34-26_chunked.txt\n",
      "- 2024-09-19 14-13-55.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-19 14-13-55.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 14-13-55_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 14-13-55_chunked.txt\n",
      "- 2024-09-26 15-04-20.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-26 15-04-20.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-26 15-04-20_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-26 15-04-20_chunked.txt\n",
      "- 2024-09-24 10-10-14.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-24 10-10-14.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 10-10-14_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 10-10-14_chunked.txt\n",
      "- 2024-09-24 11-14-23.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-24 11-14-23.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 11-14-23_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-24 11-14-23_chunked.txt\n",
      "- 2024-09-19 15-03-35.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-19 15-03-35.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 15-03-35_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 15-03-35_chunked.txt\n",
      "- 2024-09-19 16-32-50.mp3 (sequential) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "- 2024-09-19 16-32-50.mp3 (chuncked) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 16-32-50_sequential.txt\n",
      "Saved: /workspace/wordslab-voice/audio/2024-09-19 16-32-50_chunked.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Specify the directory containing mp3 files\n",
    "directory = '/workspace/wordslab-voice/audio'\n",
    "\n",
    "# Use glob to get all .mp3 files in the directory\n",
    "mp3_files = glob.glob(os.path.join(directory, '*.mp3'))\n",
    "\n",
    "# Loop through each mp3 file\n",
    "for mp3_file in mp3_files:\n",
    "    # Get the base name of the file (without directory path)\n",
    "    base_name = os.path.basename(mp3_file)\n",
    "    \n",
    "    # Replace the .mp3 extension with .txt to create a new filename\n",
    "    sequential_txt_file = base_name.replace('.mp3', '_sequential.txt')\n",
    "    chunked_txt_file = base_name.replace('.mp3', '_chunked.txt')\n",
    "    \n",
    "    # Full path of the text file to be written\n",
    "    sequential_txt_file_path = os.path.join(directory, sequential_txt_file)\n",
    "    chunked_txt_file_path = os.path.join(directory, chunked_txt_file)\n",
    "\n",
    "    # Transcribe audio with two methods\n",
    "    print(f\"- {base_name} (sequential) ...\")\n",
    "    sequential_txt = pipe(mp3_file)[\"text\"]\n",
    "    print(\"OK\")\n",
    "    \n",
    "    print(f\"- {base_name} (chunked) ...\")\n",
    "    chunked_txt = pipe(mp3_file, chunk_length_s=25, batch_size=32)[\"text\"]\n",
    "    print(\"OK\")\n",
    "    \n",
    "    # Write a text file with the same name as the mp3 file\n",
    "    with open(sequential_txt_file_path, 'w') as file:\n",
    "        file.write(sequential_txt)\n",
    "    print(f\"Saved: {sequential_txt_file_path}\")\n",
    "    \n",
    "    with open(chunked_txt_file_path, 'w') as file:\n",
    "        file.write(chunked_txt)\n",
    "    print(f\"Saved: {chunked_txt_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb434f-8120-4943-bb97-1f5d46c32c2f",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756cd710-6f24-4891-83d6-a77fc20cb2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:00:46.572835Z",
     "iopub.status.busy": "2024-09-29T19:00:46.572384Z",
     "iopub.status.idle": "2024-09-29T19:00:46.584300Z",
     "shell.execute_reply": "2024-09-29T19:00:46.583548Z",
     "shell.execute_reply.started": "2024-09-29T19:00:46.572802Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cf261-6ed1-4537-96e5-ce8a529f1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca4bac1-cabf-42ca-b404-a0c477362ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:01:25.151192Z",
     "iopub.status.busy": "2024-09-29T19:01:25.150803Z",
     "iopub.status.idle": "2024-09-29T19:01:25.175241Z",
     "shell.execute_reply": "2024-09-29T19:01:25.174795Z",
     "shell.execute_reply.started": "2024-09-29T19:01:25.151160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('vllm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944988dc-a3e0-4449-8e88-a7f2ae20cc89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:24:27.669604Z",
     "iopub.status.busy": "2024-09-29T19:24:27.669235Z",
     "iopub.status.idle": "2024-09-29T19:24:27.679802Z",
     "shell.execute_reply": "2024-09-29T19:24:27.679456Z",
     "shell.execute_reply.started": "2024-09-29T19:24:27.669575Z"
    }
   },
   "outputs": [],
   "source": [
    "test_models = {                                                                    # OpenLLM leaderboard score\n",
    "    \"llama-3.1\" : \"meta-llama/Meta-Llama-3.1-8B-Instruct\",                         # 100.0 %\n",
    "    \"llama-3.1:w8a16\" : \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16\",  # 99.8 %    \n",
    "    \"qwen-2.5\" : \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    \"qwen-2.5:w8a16\" : \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int8\",\n",
    "    \"qwen-2.5-14b:w8a16\" : \"Qwen/Qwen2.5-14B-Instruct-GPTQ-Int8\",\n",
    "    \"qwen-2.5-14b:w4a16\" : \"Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4\",\n",
    "    \"qwen-2.5-32b:w4a16\" : \"Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09510a5-b598-4049-9b90-0b4cf47f803e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:24:28.642205Z",
     "iopub.status.busy": "2024-09-29T19:24:28.641874Z",
     "iopub.status.idle": "2024-09-29T19:24:29.872638Z",
     "shell.execute_reply": "2024-09-29T19:24:29.872284Z",
     "shell.execute_reply.started": "2024-09-29T19:24:28.642181Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def format_prompt(messages, model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5811ad7e-3e58-454e-8251-81fe7c0464d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:24:32.560890Z",
     "iopub.status.busy": "2024-09-29T19:24:32.559940Z",
     "iopub.status.idle": "2024-09-29T19:24:32.570993Z",
     "shell.execute_reply": "2024-09-29T19:24:32.570181Z",
     "shell.execute_reply.started": "2024-09-29T19:24:32.560849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate VLLM with Huggingface Hub\n",
    "import os\n",
    "\n",
    "with open(\"/workspace/hftoken\", 'r') as file:\n",
    "    myhftoken = file.read().strip()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=myhftoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5770c36a-fbb2-4bdf-971f-3500a7a2d496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:24:33.251969Z",
     "iopub.status.busy": "2024-09-29T19:24:33.251636Z",
     "iopub.status.idle": "2024-09-29T19:24:33.737456Z",
     "shell.execute_reply": "2024-09-29T19:24:33.736925Z",
     "shell.execute_reply.started": "2024-09-29T19:24:33.251944Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(test_models[\"llama-3.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8156d9-341d-4b7b-94fd-b270ad5a4583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:32:00.202408Z",
     "iopub.status.busy": "2024-09-29T19:32:00.202063Z",
     "iopub.status.idle": "2024-09-29T19:32:00.409064Z",
     "shell.execute_reply": "2024-09-29T19:32:00.408723Z",
     "shell.execute_reply.started": "2024-09-29T19:32:00.202384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: /workspace/wordslab-voice/audio/2024-09-24 11-14-23_chunked.txt 21446 chars => 5581 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 10-10-14_sequential.txt 32194 chars => 8187 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-26 15-35-04_sequential.txt 60032 chars => 15458 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 10-46-15_chunked.txt 24866 chars => 6266 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 10-10-14_chunked.txt 32518 chars => 8167 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 11-39-13_sequential.txt 38849 chars => 9949 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 14-13-55_chunked.txt 46405 chars => 11883 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 13-34-26_chunked.txt 33588 chars => 8741 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 15-03-35_chunked.txt 80679 chars => 20942 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 11-14-23_sequential.txt 20560 chars => 5263 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 11-39-13_chunked.txt 40042 chars => 10240 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 12-27-09_chunked.txt 37719 chars => 9654 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-26 15-04-20_chunked.txt 26344 chars => 6692 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 14-13-55_sequential.txt 44589 chars => 11508 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-26 15-35-04_chunked.txt 61400 chars => 15618 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 13-34-26_sequential.txt 32892 chars => 8664 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 10-46-15_sequential.txt 24118 chars => 6071 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-24 12-27-09_sequential.txt 36433 chars => 9335 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 16-32-50_sequential.txt 22992 chars => 6003 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-26 15-04-20_sequential.txt 25719 chars => 6612 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 15-03-35_sequential.txt 78155 chars => 20479 tokens\n",
      "Read: /workspace/wordslab-voice/audio/2024-09-19 16-32-50_chunked.txt 23829 chars => 6187 tokens\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "directory = '/workspace/wordslab-voice/audio'\n",
    "\n",
    "text_files = glob.glob(os.path.join(directory, '*.txt'))\n",
    "\n",
    "textes = []\n",
    "\n",
    "# Loop through each mp3 file\n",
    "for text_file in text_files:\n",
    "    with open(text_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        textes.append(content)\n",
    "        print(f\"Read: {text_file} {len(content)} chars => {len(tokenizer(content)['input_ids'])} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "013b9474-f5f5-4432-88e3-eff1ec76e74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:32:47.177593Z",
     "iopub.status.busy": "2024-09-29T20:32:47.177226Z",
     "iopub.status.idle": "2024-09-29T20:32:47.184511Z",
     "shell.execute_reply": "2024-09-29T20:32:47.184193Z",
     "shell.execute_reply.started": "2024-09-29T20:32:47.177569Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def vllm_load(model):    \n",
    "    llm = LLM(model, gpu_memory_utilization=0.99, max_model_len=49152) # kv_cache_dtype=\"fp8\"\n",
    "    llm._model = model\n",
    "    return llm\n",
    "\n",
    "def vllm_generate(instruction, text, llm):    \n",
    "    message = instruction + text\n",
    "    prompt = format_prompt( [{\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français. Tu es spécialisé dans la mise en forme de texte pour le rendre plus lisibile et synthétique. Tu maîtrise parfaitement la grammaire et l'expression écrite, et tu es un expert en informatique. Tu n'invente jamais aucun élément, tu t'astreins à toujours reformuler exactement les phrases qu'on te fournit sans rien ajouter ni enlever à leur sens.\"},\n",
    "    {\"role\": \"user\", \"content\": message}], llm._model)\n",
    "    sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=len(text)+1024)\n",
    "   \n",
    "    start_time = time.time()  # Record the start time\n",
    "    outputs = llm.generate(prompt, sampling_params)\n",
    "    end_time = time.time()  # Record the end time\n",
    "\n",
    "    generated_text = outputs[0].outputs[0].text\n",
    "    tokenscount = len(outputs[0].outputs[0].token_ids)\n",
    "    tokens_per_sec = tokenscount/(end_time-start_time)\n",
    "    \n",
    "    return generated_text,tokens_per_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f7a391-c90f-4e3c-8735-6a094c7b8b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:25:25.596502Z",
     "iopub.status.busy": "2024-09-29T19:25:25.596303Z",
     "iopub.status.idle": "2024-09-29T19:25:42.851312Z",
     "shell.execute_reply": "2024-09-29T19:25:42.850903Z",
     "shell.execute_reply.started": "2024-09-29T19:25:25.596495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-29 21:25:25 arg_utils.py:930] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 09-29 21:25:25 config.py:1010] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 09-29 21:25:25 llm_engine.py:226] Initializing an LLM engine (v0.6.1.dev238+ge2c6e0a82) with config: model='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16', speculative_config=None, tokenizer='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=49152, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 09-29 21:25:26 utils.py:747] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 09-29 21:25:26 model_runner.py:1014] Starting to load model neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a16...\n",
      "INFO 09-29 21:25:26 compressed_tensors_wNa16.py:84] Using MarlinLinearKernel for CompressedTensorsWNA16\n",
      "INFO 09-29 21:25:27 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2915ce87b34486d92f17e5e9992f816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-29 21:25:32 model_runner.py:1025] Loading model weights took 8.4927 GB\n",
      "INFO 09-29 21:25:32 gpu_executor.py:122] # GPU blocks: 7096, # CPU blocks: 2048\n",
      "INFO 09-29 21:25:33 model_runner.py:1329] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-29 21:25:33 model_runner.py:1333] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-29 21:25:42 model_runner.py:1456] Graph capturing finished in 10 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = vllm_load(test_models[\"llama-3.1:w8a16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d5a028-82e3-441f-bc89-2087db54f450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:31:24.904806Z",
     "iopub.status.busy": "2024-09-29T19:31:24.903690Z",
     "iopub.status.idle": "2024-09-29T19:31:24.909241Z",
     "shell.execute_reply": "2024-09-29T19:31:24.908253Z",
     "shell.execute_reply.started": "2024-09-29T19:31:24.904773Z"
    }
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Le texte ci-dessous est le résultat d'un transcription automatique de la voix du présentateur d'une conférence sur l'intelligence artificielle. \n",
    "Cette transcription est imparfaite : erreurs, mots incomplets, poncutation manquante, hésitations, interruptions ...\n",
    "Ton travail consiste à répéter strictement le texte fourni ci-dessous, mais en corrigeant sa syntaxe et sa mise en forme :\n",
    "- reformulation sous forme de phrases équivalentes mais bien contruites et sans fautes d'orthographe\n",
    "- ajout de sauts de lignes de paragraphes chaque fois que le présentateur change de sujet\n",
    "- génération de titres et sous-titres de chapitres au format Markdown\n",
    "\n",
    "Voici le texte à mettre en forme :\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b22b22cc-b1ba-4474-b5e4-8c47381369bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:35:01.669022Z",
     "iopub.status.busy": "2024-09-29T20:35:01.668068Z",
     "iopub.status.idle": "2024-09-29T20:35:16.427217Z",
     "shell.execute_reply": "2024-09-29T20:35:16.426869Z",
     "shell.execute_reply.started": "2024-09-29T20:35:01.668995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████| 1/1 [00:14<00:00, 14.45s/it, est. speed input: 407.78 toks/s, output: 78.50 toks/s]\n"
     ]
    }
   ],
   "source": [
    "text, tokens_per_sec = vllm_generate(instruction, textes[0], llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22f27370-e3b5-4099-b6db-c53210486014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T20:35:16.427926Z",
     "iopub.status.busy": "2024-09-29T20:35:16.427801Z",
     "iopub.status.idle": "2024-09-29T20:35:16.430613Z",
     "shell.execute_reply": "2024-09-29T20:35:16.430339Z",
     "shell.execute_reply.started": "2024-09-29T20:35:16.427915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Introduction à l'Intelligence Artificielle\n",
       "\n",
       "## Les Domaines de Recherche dans l'IA\n",
       "\n",
       "Voilà, alors, sur tous ces sujets, on a vu que chaque phrase qu'on a dite là-dedans, en fait, c'est un domaine de recherche à part entière, encore aujourd'hui. Il n'y a pas de mode opératoire, de règles, etc. Donc, comment aller plus loin, comment faire de la veille ?\n",
       "\n",
       "## La Veille et les Ressources\n",
       "\n",
       "On a prévu au delà de cette formation tronc commun d'utiliser nos réunions innovation hebdomadaires. Robin a été intervenu pour essayer de vous montrer comment faire pour rechercher quand on sait pas. On peut commencer par YouTube, tout bêtement. Il ya plein de vidéos, plein d'explications externes. Quand vous commencez à repérer les gens qui sont intéressants, qui ont le plus de vue là-dessus, alors c'est quand même... En général, il y a une corrélation entre la popularité et la qualité des contenus.\n",
       "\n",
       "## Les Communautés Spontanées\n",
       "\n",
       "Il ya des communautés spontanées qui se créent en ligne. C'est pour moi extrêmement impressionnant. C'est assez incroyable. Les trucs commencent par 3 personnes qui se réunissent et à la fin ils sont plusieurs milliers. Il ya deux exemples de ça.\n",
       "\n",
       "## Le Premier Exemple\n",
       "\n",
       "Un exemple est la formation en début d'année, où les gens se sont dit : \"Voilà, ça fait à peu près un an qu'on fait des LM en production. Qu'est-ce qu'on a appris ?\" Il ya quelques personnes dans la communauté assez connues. Ils sont mis à deux ou trois au départ. Ils ont dit : \"On va faire une formation où c'est un peu dans le même format qu'on fait là, avec très peu de slides et c'est juste j'essaye de restituer un peu dans l'ordre et correctement ce que j'ai appris donné un an de LM.\" Ils ont commencé à prévoir trois ou quatre sessions, je ne sais plus. Je me suis inscrit à ce moment-là. Et après, ça a fini en une conférence où il y a eu plus de 40 sessions et tous les grands noms du domaine sont venus chacun contribuer leur truc.\n",
       "\n",
       "## Le Deuxième Exemple\n",
       "\n",
       "Un autre exemple est la communauté QDA Mode, qui a démarré avec trois personnes et a fini par avoir 9 000 personnes actives. Ils ont créé un serveur Discord et une chaîne YouTube pour partager leurs connaissances et leurs expériences.\n",
       "\n",
       "## L'Importance de la Veille\n",
       "\n",
       "L'importance de la veille est de repérer les acteurs clés et les communautés qui se créent en ligne. Cela nous permet de nous tenir informés et de nous adapter aux évolutions du domaine.\n",
       "\n",
       "## Les Tâches dans le Machine Learning\n",
       "\n",
       "Dans le machine learning, il ya différentes tâches que l'on peut effectuer, comme la classification, la segmentation, la détection d'objets, etc. Il ya une nomenclature de toutes les tâches qu'on peut faire sur l'image, le texte, la voix, etc.\n",
       "\n",
       "## Les Benchmark Académiques\n",
       "\n",
       "Il ya des benchmark académiques qui mesurent les capacités d'un modèle sur une tâche particulière. Cela nous permet de comparer les performances des modèles et de voir comment on a amélioré les performances sur les benchmarkes au fil des années.\n",
       "\n",
       "## L'Importance de Connaître les Tâches\n",
       "\n",
       "Connaître les tâches est important pour faire une bonne formation en IA. Il faut être capable de distinguer les différentes tâches et de les séparer pour faire une conception de projet efficace.\n",
       "\n",
       "## L'Apprentissage par l'Exemple\n",
       "\n",
       "L'apprentissage par l'exemple est un principe fondamental du machine learning. On apprend par l'exemple en ajustant les paramètres d'un modèle pour minimiser l'erreur sur des exemples de données.\n",
       "\n",
       "## L'Ajustement des Paramètres\n",
       "\n",
       "L'ajustement des paramètres est un processus crucial dans l'apprentissage par l'exemple. On ajuste les paramètres pour minimiser l'erreur sur des exemples de données et pour trouver un modèle qui prédit correctement les résultats.\n",
       "\n",
       "## La Construction d'un Modèle\n",
       "\n",
       "La construction d'un modèle est un processus complexe qui implique l'ajustement des paramètres pour minimiser l'erreur sur des exemples de données. Le modèle final est imparfait, mais il est capable de prédire correctement les résultats sur de nouvelles données.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "En conclusion, la veille et la connaissance des tâches sont essentiels pour faire une bonne formation en IA. L'apprentissage par l'exemple et l'ajustement des paramètres sont des principes fondamentaux du machine learning. La construction d'un modèle est un processus complexe qui implique l'ajustement des paramètres pour minimiser l'erreur sur des exemples de données."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5918c-d376-4241-84d3-afd14f6a9cf9",
   "metadata": {},
   "source": [
    "## Nvidia Nemo ASR\n",
    "\n",
    "https://developer.nvidia.com/blog/accelerating-leaderboard-topping-asr-models-10x-with-nvidia-nemo/\n",
    "\n",
    "https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/asr/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfadc0-ad14-4196-8424-e29204fcdd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
