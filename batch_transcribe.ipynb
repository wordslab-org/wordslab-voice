{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e014d6c1-2727-4e4a-83ff-203f8e7b3f2a",
   "metadata": {},
   "source": [
    "# Transcribe audio files in batch mode as fast as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d1fda0-bbd8-4b3e-bd9c-57164c860bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:25:09.596992Z",
     "iopub.status.busy": "2024-09-29T07:25:09.596545Z",
     "iopub.status.idle": "2024-09-29T07:25:09.602935Z",
     "shell.execute_reply": "2024-09-29T07:25:09.601931Z",
     "shell.execute_reply.started": "2024-09-29T07:25:09.596961Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56df76d7-4856-45fc-9f91-e361b1bb4d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:07:17.512126Z",
     "iopub.status.busy": "2024-09-29T07:07:17.511762Z",
     "iopub.status.idle": "2024-09-29T07:07:17.522523Z",
     "shell.execute_reply": "2024-09-29T07:07:17.522269Z",
     "shell.execute_reply.started": "2024-09-29T07:07:17.512102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158edb7-33a0-4628-9eaf-9db3cce2e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9039795-f1f1-49d1-a0b6-cf92cf22c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11130d56-5a5b-40e8-b85c-d90dfd9577f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:25:11.304413Z",
     "iopub.status.busy": "2024-09-29T07:25:11.303756Z",
     "iopub.status.idle": "2024-09-29T07:25:11.314357Z",
     "shell.execute_reply": "2024-09-29T07:25:11.313938Z",
     "shell.execute_reply.started": "2024-09-29T07:25:11.304385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.45.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba96ccf-f1b0-4097-aa8f-209eae467360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:25:11.685464Z",
     "iopub.status.busy": "2024-09-29T07:25:11.685140Z",
     "iopub.status.idle": "2024-09-29T07:25:11.691436Z",
     "shell.execute_reply": "2024-09-29T07:25:11.691172Z",
     "shell.execute_reply.started": "2024-09-29T07:25:11.685441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.34.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('accelerate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196fc82-43f8-490a-a9e9-e8fb90427038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73db5e4-7516-484a-a76e-05aed1ed1b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T07:30:55.669480Z",
     "iopub.status.busy": "2024-09-29T07:30:55.669060Z",
     "iopub.status.idle": "2024-09-29T07:30:55.679344Z",
     "shell.execute_reply": "2024-09-29T07:30:55.678910Z",
     "shell.execute_reply.started": "2024-09-29T07:30:55.669448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('flash_attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44703518-d75c-4223-93b7-92457811f4b0",
   "metadata": {},
   "source": [
    "## Huggingface Whisper\n",
    "\n",
    "https://github.com/huggingface/speech-to-speech/blob/main/STT/whisper_stt_handler.py\n",
    "\n",
    "https://huggingface.co/eustlb/distil-large-v3-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcb2fd4-e273-4125-8269-7874e7516d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:20:09.705627Z",
     "iopub.status.busy": "2024-09-29T14:20:09.705304Z",
     "iopub.status.idle": "2024-09-29T14:20:13.334587Z",
     "shell.execute_reply": "2024-09-29T14:20:13.334213Z",
     "shell.execute_reply.started": "2024-09-29T14:20:09.705605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"eustlb/distil-large-v3-fr\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, \n",
    "    use_safetensors=True, low_cpu_mem_usage=True, device_map=device, \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype\n",
    ")\n",
    "\n",
    "# warmup\n",
    "dummy_input = torch.randn( (1, model.config.num_mel_bins, 3000), dtype=torch_dtype, device=device)\n",
    "_ = model.generate(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1865cd0b-eb16-4c1c-8064-4a6edac0cf23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:20:58.286337Z",
     "iopub.status.busy": "2024-09-29T14:20:58.285968Z",
     "iopub.status.idle": "2024-09-29T14:21:25.068208Z",
     "shell.execute_reply": "2024-09-29T14:21:25.067815Z",
     "shell.execute_reply.started": "2024-09-29T14:20:58.286310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ok, donc dans la première partie, on a fait beaucoup de choses, on s'est posé beaucoup de questions pour pouvoir cadrer, sélectionner, identifier des projets à Basse-Dia qui soient pertinents. La pha\n"
     ]
    }
   ],
   "source": [
    "# ./audio/2024-09-19 16-32-50.mp3\n",
    "# - batch size 64, flash attention 2, no compile: 6.14 sec\n",
    "# - batch size 64, sdpa attention, compile default with fullgraph: 18 sec (first test) / 34 sec (second test)\n",
    "# => follow line by line the example of https://huggingface.co/eustlb/distil-large-v3-fr, it is the fastest combination\n",
    "\n",
    "# Test with 2 mp3 files\n",
    "# - small: 24 min 47 sec (1487 sec), 22.7 MB file\n",
    "# - big : 1h 24 min 19 sec (5059 sec), 77.2 MB file\n",
    "\n",
    "# Sequential long-form: pipe(mp3file)\n",
    "# - gpu memory = 3.1 GB -> 27 sec / 94 sec\n",
    "\n",
    "# Chunked long-form: pipe(mp3file, chunk_length_s=25, batch_size=xxx)\n",
    "# batch size 1 : gpu memory = 3.1 GB -> 33 sec / 111 sec\n",
    "# batch size 8 : gpu memory = 3.6 GB -> 13 sec / 46 sec\n",
    "# batch size 16 : gpu memory = 4.4 GB -> 11 sec / 37 sec\n",
    "# batch size 32 : gpu memory = 5.1 GB -> 9.5 sec / 34 sec\n",
    "# batch size 64 : gpu memory = 7.2 GB -> 10.3 sec / 31 sec\n",
    "# batch size 128 : gpu memory = 11 GB -> 9.3 sec / 33 sec\n",
    "# Chunked attention: pipe(mp3file, chunk_length_s=25, batch_size=xxx)\n",
    "\n",
    "# Sequential long-form algorithm + batch_size 2: pipe([mp3file1, mp3file2], batch_size=2)\n",
    "# => RuntimeError: The expanded size of the tensor (505922) must match the existing size (148730) at non-singleton dimension 1.  Target sizes: [128, 505922].  Tensor sizes: [128, 148730]\n",
    "\n",
    "result = pipe(\"./audio/2024-09-19 16-32-50.mp3\")\n",
    "print(result[\"text\"][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67d5b25-eb54-4118-822c-60447350dfa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:23:39.968711Z",
     "iopub.status.busy": "2024-09-29T14:23:39.968329Z",
     "iopub.status.idle": "2024-09-29T14:25:10.907269Z",
     "shell.execute_reply": "2024-09-29T14:25:10.906719Z",
     "shell.execute_reply.started": "2024-09-29T14:23:39.968686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/wordslab-voice/.venv/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ok. Donc, on poursuit notre énumération de tous les aspects à prendre en compte pour voir si un projet doit être fait, faisable et rentable, et raisonnable en matière d'environnement, etc. Donc, poin\n"
     ]
    }
   ],
   "source": [
    "result = pipe(\"./audio/2024-09-19 15-03-35.mp3\")\n",
    "print(result[\"text\"][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d94411-e680-405a-9343-f5069b39ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe([\"./audio/2024-09-19 15-03-35.mp3\",\"./audio/2024-09-19 16-32-50.mp3\"], batch_size=2)\n",
    "for result in results: print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206c4ef-00f8-4950-a039-61073d111d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e5918c-d376-4241-84d3-afd14f6a9cf9",
   "metadata": {},
   "source": [
    "## Nvidia Nemo ASR\n",
    "\n",
    "https://developer.nvidia.com/blog/accelerating-leaderboard-topping-asr-models-10x-with-nvidia-nemo/\n",
    "\n",
    "https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/asr/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfadc0-ad14-4196-8424-e29204fcdd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-voice",
   "language": "python",
   "name": "wordslab-voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
